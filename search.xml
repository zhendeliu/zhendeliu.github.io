<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AI算法面试问题-机器学习（一）</title>
    <url>/2021/10/02/AI%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="问题列表"><a href="#问题列表" class="headerlink" title="问题列表"></a>问题列表</h1><ol>
<li>详细说一下支持向量机的原理</li>
<li>数据归一化的原因</li>
<li>哪些算法不需要归一化处理</li>
<li>树形结构为什么不需要归一化</li>
<li>常用的距离计算有哪些，有什么区别</li>
<li>机器学习项目的流程</li>
<li>Logistic Regression 逻辑回归的原理</li>
<li>逻辑回归为什么要特征离散化</li>
<li>overfitting怎么解决</li>
<li>逻辑回归和SVM的区别与联系</li>
</ol>
<span id="more"></span>

<p>面试问题来源机器学习面试150题 <a href="https://www.zhihu.com/column/c_1284826692855771136">https://www.zhihu.com/column/c_1284826692855771136</a></p>
<h1 id="问题及解答"><a href="#问题及解答" class="headerlink" title="问题及解答"></a>问题及解答</h1><h2 id="详细说一下支持向量机的原理"><a href="#详细说一下支持向量机的原理" class="headerlink" title="详细说一下支持向量机的原理"></a>详细说一下支持向量机的原理</h2>]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>总结</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>AI算法面试问题-机器学习（三）</title>
    <url>/2021/10/02/AI%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>AI算法面试问题-机器学习（二）</title>
    <url>/2021/10/02/AI%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>OpenCV图像处理基础（三）</title>
    <url>/2021/09/29/OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="灰度图"><a href="#灰度图" class="headerlink" title="灰度图"></a>灰度图</h1><h1 id="灰度直方图等"><a href="#灰度直方图等" class="headerlink" title="灰度直方图等"></a>灰度直方图等</h1><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>基础操作</tag>
        <tag>噪音</tag>
        <tag>灰度图</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV图像处理基础（一）</title>
    <url>/2021/09/29/OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>数字图像基础</p>
<p>读、写、显示（图片、视频）</p>
<p>缩放、补边、裁剪</p>
<p>绘制形状</p>
<p>书写文字</p>
<span id="more"></span>

<h1 id="图像的数字表示"><a href="#图像的数字表示" class="headerlink" title="图像的数字表示"></a>图像的数字表示</h1><p>在计算机系统中存储的是每张图像每个像素点的值</p>
<p>灰度图，单通道图像也就是8位图像，每个像素点的值占8字节，00000000-11111111也就是0-255</p>
<p>RGB/BGR图像，是三通道图像，也就是24位图像，每个像素点的值占24字节，也就是三个通道每个通道的值占8字节0-255</p>
<p>灰度图也可以表示成三通道，不过三通道上的值是相等的</p>
<p>像素值为0表示黑色，255表示白色</p>
<p>32位图像在24位的基础上增加了一个alpha分量，该分量用于记录图像的透明度信息。</p>
<h1 id="读、写、显示"><a href="#读、写、显示" class="headerlink" title="读、写、显示"></a>读、写、显示</h1><h2 id="图片读取"><a href="#图片读取" class="headerlink" title="图片读取"></a>图片读取</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 读取函数imread()</span></span><br><span class="line">img = cv2.imread(<span class="string">&quot;Path.jpg/png&quot;</span>)</span><br><span class="line"><span class="comment"># 显示函数 imshow()</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;窗口名称&#x27;</span>,img)</span><br><span class="line"><span class="comment"># 写入函数 imwrite()</span></span><br><span class="line">cv2.imwrite(<span class="string">&#x27;写入的文件名.jpg&#x27;</span>,img)</span><br><span class="line"><span class="comment"># cv2.IMWRITE_JPEG_QUALITY指定jpg质量，范围0到100，默认95，越高画质越好，文件越大</span></span><br><span class="line">cv2.imwrite(<span class="string">&#x27;写入的文件名.jpg&#x27;</span>, img, (cv2.IMWRITE_JPEG_QUALITY, <span class="number">80</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># cv2.IMWRITE_PNG_COMPRESSION指定png质量，范围0到9，默认3，越高文件越小，画质越差</span></span><br><span class="line">cv2.imwrite(<span class="string">&#x27;写入的文件名.png&#x27;</span>, img, (cv2.IMWRITE_PNG_COMPRESSION, <span class="number">5</span>))</span><br></pre></td></tr></table></figure>

<h2 id="显示图片需要对窗口进行设置"><a href="#显示图片需要对窗口进行设置" class="headerlink" title="显示图片需要对窗口进行设置"></a>显示图片需要对窗口进行设置</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.imshow(<span class="string">&#x27;窗口名称&#x27;</span>,img)</span><br><span class="line">cv2.waitkey(<span class="number">0</span>)</span><br><span class="line">cv2.destoryAllWindows()</span><br></pre></td></tr></table></figure>

<p><code>cv2.waitKey()</code> 是键盘绑定函数，可以设置毫秒级数值，如果是0会一直等待，也可以设置为指定字母，比如a</p>
<p><code>cv2.destoryAllWindows()</code>销毁所有创建的窗口</p>
<h2 id="视频读取，显示"><a href="#视频读取，显示" class="headerlink" title="视频读取，显示"></a>视频读取，显示</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cap = cv2.VideoCapture(<span class="string">&#x27;视频名称.mp4/avi&#x27;</span>) <span class="comment"># 获取视频</span></span><br><span class="line"><span class="comment"># cap = cv2.VideoCapture(0) # 获取摄像头 0内置 1外置摄像头</span></span><br><span class="line"><span class="comment"># 视频显示：while循环显示视频的每一帧</span></span><br><span class="line"><span class="comment"># 使用read()获取的视频帧，将每一帧显示100ms,如果期间检测到‘q‘则退出，关闭窗口</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  reg,frame = cap.read()</span><br><span class="line">  cv2.imshow(<span class="string">&#x27;caputre&#x27;</span>,frame)</span><br><span class="line">  <span class="keyword">if</span> cv2.waitkey(<span class="number">100</span>) <span class="keyword">and</span> <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h1 id="缩放，补边，裁剪"><a href="#缩放，补边，裁剪" class="headerlink" title="缩放，补边，裁剪"></a>缩放，补边，裁剪</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 缩放成200x200的方形图像</span></span><br><span class="line">img_200x200 = cv2.resize(img, (<span class="number">200</span>, <span class="number">200</span>))</span><br><span class="line"><span class="comment"># 根据缩放比例来</span></span><br><span class="line"><span class="comment"># 默认线性插值 cv2.INTER_LINEAR</span></span><br><span class="line">img = cv2.resize(img,(<span class="number">0</span>,<span class="number">0</span>),fx=<span class="number">0.5</span>,fy=<span class="number">0.5</span>,interpolation=cv2.INTER_NEAREST) <span class="comment"># 邻近插值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上下左右分布补边50，40，30，20宽，常数填充 都是黑边</span></span><br><span class="line">img = cv2.copyMakeBorder(img, <span class="number">50</span>, <span class="number">40</span>, <span class="number">30</span>, <span class="number">20</span>,cv2.BORDER_CONSTANT, value=(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据切片来做裁剪</span></span><br><span class="line">imgCropped = img[<span class="number">50</span>:<span class="number">250</span>,<span class="number">120</span>:<span class="number">330</span>]</span><br></pre></td></tr></table></figure>



<h1 id="绘制形状"><a href="#绘制形状" class="headerlink" title="绘制形状"></a>绘制形状</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cv2.line() 图像，起点，终点，画笔颜色，线宽</span></span><br><span class="line">img = cv2.line(img,(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">511</span>,<span class="number">511</span>),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">5</span>)  </span><br><span class="line"><span class="comment"># cv2.circle() 图像，圆心，半径，颜色，-1是表示一个封闭的图形</span></span><br><span class="line">img = cv2.circle(img,(<span class="number">447</span>,<span class="number">63</span>),<span class="number">63</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),-<span class="number">1</span>)  </span><br><span class="line"><span class="comment"># cv2.rectangle() 图像，左上角，右下角，颜色，线宽</span></span><br><span class="line">img = cv2.rectangle(img,(<span class="number">384</span>,<span class="number">0</span>),(<span class="number">510</span>,<span class="number">128</span>),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">3</span>) </span><br><span class="line"><span class="comment"># cv2.ellipse()</span></span><br><span class="line">img = cv2.ellipse(img,(<span class="number">256</span>,<span class="number">256</span>),(<span class="number">100</span>,<span class="number">50</span>),<span class="number">0</span>,<span class="number">0</span>,<span class="number">180</span>,<span class="number">255</span>,-<span class="number">1</span>) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="书写文字"><a href="#书写文字" class="headerlink" title="书写文字"></a>书写文字</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cv2.putText()</span></span><br><span class="line"><span class="comment"># 各参数依次是：图片，添加的文字，左上角坐标，字体，字体大小，颜色，字体粗细</span></span><br><span class="line">img = cv2.putText(img, <span class="built_in">str</span>, (<span class="number">123</span>,<span class="number">456</span>)), font, <span class="number">2</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>基础操作</tag>
        <tag>噪音</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch框架基础（一）</title>
    <url>/2021/09/05/Pytorch%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1>]]></content>
      <categories>
        <category>学习</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>基础操作</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch框架基础（二）</title>
    <url>/2021/09/06/Pytorch%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1>]]></content>
      <categories>
        <category>学习</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>基础操作</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>cv算法面试问题总结（一）</title>
    <url>/2021/09/29/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="问题列表："><a href="#问题列表：" class="headerlink" title="问题列表："></a>问题列表：</h1><ol>
<li>CNN的特点和优势</li>
<li>decent 反卷积的作用</li>
<li>dropout 的作用和实现机制</li>
<li>深度学习中有哪些可加快收敛（降低训练难度）的方法</li>
<li>什么导致过拟合，如何防止过拟合</li>
<li>**LSTM防止梯度弥散和爆炸 **</li>
<li>Local Connected Conv</li>
<li>神经网络权值初始化的方式和区别</li>
<li>简述Convolution,pooling,和Normalization在卷积中的作用</li>
<li>Dilated conv(空洞卷积)优缺点和应用场景</li>
</ol>
<span id="more"></span>

<h1 id="常见问题及回答总结"><a href="#常见问题及回答总结" class="headerlink" title="常见问题及回答总结"></a>常见问题及回答总结</h1><h2 id="CNN的特点和优势"><a href="#CNN的特点和优势" class="headerlink" title="CNN的特点和优势"></a>CNN的特点和优势</h2><ol>
<li>改变全链接为局部连接，可以提取局部特征</li>
<li>权值共享，减少参数数量，降低训练难度（空间和时间都降低）</li>
<li>降维， 通过池化或者卷积stride实现</li>
<li>多层次结构：降低层次的局部特征组合为较高层次的特征。不同层次的特征应对不同任务</li>
<li>可以完全共享也可以局部共享 （比如眼睛鼻子嘴巴等位置样式固定的可以用和脸部不一样的卷积核）</li>
</ol>
<h2 id="decent的作用"><a href="#decent的作用" class="headerlink" title="decent的作用"></a>decent的作用</h2><ol>
<li>CNN可视化，将conv中得到的feature map还原到像素空间，观察特定的feature map对哪些图案比较敏感</li>
<li>Upsampling 上采样</li>
<li>Unsupervised learning 重构图像</li>
</ol>
<h2 id="dropout-的作用和实现机制"><a href="#dropout-的作用和实现机制" class="headerlink" title="dropout 的作用和实现机制"></a>dropout 的作用和实现机制</h2><ol>
<li>原理是 在深度学习网络训练中对于输入层和隐藏层的神经网络单元 按照一定的概率P（伯努利分布） 暂时性！！！的丢弃。对于随机梯度下降，由于是随机丢弃，所以对于每一个mini-batch都在训练不同的网络</li>
<li>作用是防止过拟合，提高效果</li>
<li>缺点是 收敛速度减慢，由于每一次迭代只有一部分参数更新，导致梯度下降的速度减慢</li>
<li>测试时，每个权重值需要乘概率p <a href="https://zhuanlan.zhihu.com/p/38200980">https://zhuanlan.zhihu.com/p/38200980</a> dropout 必读</li>
</ol>
<h2 id="深度学习中有哪些可加快收敛（降低训练难度）的方法"><a href="#深度学习中有哪些可加快收敛（降低训练难度）的方法" class="headerlink" title="深度学习中有哪些可加快收敛（降低训练难度）的方法"></a>深度学习中有哪些可加快收敛（降低训练难度）的方法</h2><ol>
<li>bottleneck瓶颈结构： 在计算比较大的卷积层的之前使用一个1<em>1的卷积来压缩大卷积层输入特征图的通道数，用来减少计算量。大卷积层完成之后按照实际情况，有时候需要1</em>1的卷积来将大卷积层的输出特征图的通道数复原</li>
<li>残差 （还不是很明白）</li>
<li>学习率，步长，动量</li>
<li>优化方法</li>
<li>预训练</li>
</ol>
<h2 id="什么导致过拟合，如何防止过拟合"><a href="#什么导致过拟合，如何防止过拟合" class="headerlink" title="什么导致过拟合，如何防止过拟合"></a>什么导致过拟合，如何防止过拟合</h2><ol>
<li>过拟合的原因： 样本量过小，样本抽取不均衡噪音过多，参数太多模型复杂度高，权值迭代次数足够多拟合了训练样本中的噪音和不具代表性的特征</li>
<li>防止方法：<ol>
<li>数据增强 data argumentation</li>
<li>early stop</li>
<li>dropout</li>
<li>Batch Normalization</li>
<li>使用更简单的模型</li>
<li>参数正则化： 通过一定方法使神经网络中的部分神经元关闭，降低模型的复杂程度。正则化就是为了减小测试误差的，虽然有的时候可能会以增大训练误差为代价。正则化是为了显著的减小方差而较小的增大偏差。也就是提升泛化能力</li>
<li>加噪音（输入数噪声，权重噪声，响应结果里面加噪声）</li>
<li>freeze预训练网络中的某几层 #代码 <a href="https://blog.csdn.net/weixin_41712499/article/details/111295683">https://blog.csdn.net/weixin_41712499/article/details/111295683</a></li>
<li>结合多个模型 <ol>
<li>Bagging: 可以将其理解为一个分段函数，使用不同的模型拟合不同部分的训练集。如随机森林就是训练了一堆互不关联的决策树</li>
<li>Boosting：使用多个模型最后将模型的输出加权平均</li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="LSTM防止梯度弥散和爆炸"><a href="#LSTM防止梯度弥散和爆炸" class="headerlink" title="LSTM防止梯度弥散和爆炸"></a>LSTM防止梯度弥散和爆炸</h2><h2 id="Local-Connected-Conv"><a href="#Local-Connected-Conv" class="headerlink" title="Local Connected Conv"></a>Local Connected Conv</h2><ol>
<li>人脸在不同的区域存在不同的特征（眼睛／鼻子／嘴的分布位置相对固定），当不存在全局的局部特征分布时，Local-Conv更适合特征的提取</li>
</ol>
<h2 id="神经网络权值初始化的方式和区别"><a href="#神经网络权值初始化的方式和区别" class="headerlink" title="神经网络权值初始化的方式和区别"></a>神经网络权值初始化的方式和区别</h2><p>​    详见权值初始化blog</p>
<ol>
<li>常量初始化</li>
<li>随机高斯初始化： 将权重初始化为固定的均值和方差（例如均值取0，方差取0.01）如果初始的方差小，如0.1，就会导致在前向传播过程中，不同的层的输入不断减小。会导致权重的更新速度很慢很慢。初始化的方差如果太大，就会使得每一层的输出越来越大。形如tanh激活函数，就会容易导致梯度饱和的现象</li>
<li>均匀分布初始化</li>
<li>Xavier初始化</li>
<li>双线性初始化</li>
<li>msra初始化</li>
</ol>
<h2 id="简述Convolution-pooling-和Normalization在卷积中的作用"><a href="#简述Convolution-pooling-和Normalization在卷积中的作用" class="headerlink" title="简述Convolution,pooling,和Normalization在卷积中的作用"></a>简述Convolution,pooling,和Normalization在卷积中的作用</h2><ol>
<li>Convolution：通过卷积核运算，提取卷积核希望提取的特征</li>
<li>pooling层 减小图像大小，加速计算，使其检测出的特征更加健壮</li>
<li>fully connected： 用来做分类</li>
<li>激活层 使得函数更加复杂</li>
<li>Batch Normalization：<ol>
<li>背景：深度学习中数据分布在某一层开始有明显的偏移，网络加深会加剧，导致模型优化的难度增加，也就是梯度弥散。</li>
<li>方法：在每个卷积层之后重新调整数据分布，解决梯度问题。在网络每一层输入前，先做归一化处理，加一个归一化层。但并不是盲目加。变换重构，引入可学习的参数r,B, 从而控制归一化尽可能不影响特征提取</li>
<li>好处：降低对参数初始化的依赖。可使用更高的学习率，加速训练。一定程度上增加了泛化能力，可以取代dropout</li>
</ol>
</li>
</ol>
<h2 id="Dilated-conv-空洞卷积-优缺点和应用场景"><a href="#Dilated-conv-空洞卷积-优缺点和应用场景" class="headerlink" title="Dilated conv(空洞卷积)优缺点和应用场景"></a>Dilated conv(空洞卷积)优缺点和应用场景</h2><ol>
<li>背景： FCN全卷积的语义分割问题中，需要输入图像和输出图像的size保持一致。若使用池化层，会降低size之后需要上采样，导致特征信息丢失精度降低。若使用较小的卷积核，可保持size一致，但需要增大特征图通道数会导致计算量较大。</li>
<li>空洞卷积，在特征图上进行0填充扩大特征图size，既能保持感受野又能保持计算点不变</li>
</ol>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>总结</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>cv算法面试问题总结（七）</title>
    <url>/2021/10/06/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%83%EF%BC%89/</url>
    <content><![CDATA[<p>如何解决深度学习中模型训练效果不佳的情况？<br>神经网络中，是否隐藏层如果具有足够数量的单位，它就可以近似任何连续函数？<br>为什么更深的网络更好？<br>更多的数据是否有利于更深的神经网络？<br>不平衡数据是否会影响神经网络的分类效果？<br>无监督降维提供的是帮助还是摧毁？<br>是否可以将任何非线性作为激活函数?<br>批大小如何影响测试正确率？<br>初始化如何影响训练?<br>不同层的权重是否以不同的速度收敛？ </p>
<p>正则化如何影响权重？<br>什么是fine-tuning？<br>什么是边框回归Bounding-Box regression，以及为什么要做、怎么做<br>请阐述下Selective Search的主要思想<br>什么是非极大值抑制（NMS）？<br>什么是深度学习中的anchor？<br>CNN的特点以及优势<br>深度学习中有什么加快收敛/降低训练难度的方法？<br>请写出链式法则并证明<br>请写出Batch Normalization的计算方法及其应用</p>
<span id="more"></span>

]]></content>
  </entry>
  <entry>
    <title>cv算法面试问题总结（三）</title>
    <url>/2021/09/29/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="问题列表"><a href="#问题列表" class="headerlink" title="问题列表"></a>问题列表</h1><ol>
<li>mAP计算</li>
<li>为什么要做特征归一化，标准化</li>
<li>常用的归一化和标准化方法</li>
<li>为什么线性回归使用mse作文损失函数</li>
<li>神经网络的深度和宽度分别是什么</li>
<li>下采样的作用？下采样的方法</li>
<li>上采样的原理和常用的方法</li>
<li>模型的FLOPs（计算量）是什么？怎么计算？</li>
<li>什么是深度可分离卷积？作用？</li>
<li>转置卷积的原理</li>
</ol>
<span id="more"></span>

<h1 id="问题及解答"><a href="#问题及解答" class="headerlink" title="问题及解答"></a>问题及解答</h1><h2 id="mAP计算"><a href="#mAP计算" class="headerlink" title="mAP计算"></a>mAP计算</h2><h2 id="为什么要做特征归一化，标准化"><a href="#为什么要做特征归一化，标准化" class="headerlink" title="为什么要做特征归一化，标准化"></a>为什么要做特征归一化，标准化</h2><h2 id="常用的归一化和标准化方法"><a href="#常用的归一化和标准化方法" class="headerlink" title="常用的归一化和标准化方法"></a>常用的归一化和标准化方法</h2><h2 id="为什么线性回归使用mse作文损失函数"><a href="#为什么线性回归使用mse作文损失函数" class="headerlink" title="为什么线性回归使用mse作文损失函数"></a>为什么线性回归使用mse作文损失函数</h2><h2 id="神经网络的深度和宽度分别是什么"><a href="#神经网络的深度和宽度分别是什么" class="headerlink" title="神经网络的深度和宽度分别是什么"></a>神经网络的深度和宽度分别是什么</h2><h2 id="下采样的作用？下采样的方法"><a href="#下采样的作用？下采样的方法" class="headerlink" title="下采样的作用？下采样的方法"></a>下采样的作用？下采样的方法</h2><h2 id="上采样的原理和常用的方法"><a href="#上采样的原理和常用的方法" class="headerlink" title="上采样的原理和常用的方法"></a>上采样的原理和常用的方法</h2><h2 id="模型的FLOPs（计算量）是什么？怎么计算？"><a href="#模型的FLOPs（计算量）是什么？怎么计算？" class="headerlink" title="模型的FLOPs（计算量）是什么？怎么计算？"></a>模型的FLOPs（计算量）是什么？怎么计算？</h2><h2 id="什么是深度可分离卷积？作用？"><a href="#什么是深度可分离卷积？作用？" class="headerlink" title="什么是深度可分离卷积？作用？"></a>什么是深度可分离卷积？作用？</h2><h2 id="转置卷积的原理"><a href="#转置卷积的原理" class="headerlink" title="转置卷积的原理"></a>转置卷积的原理</h2>]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>总结</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>cv算法面试问题总结（九）</title>
    <url>/2021/10/06/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B9%9D%EF%BC%89/</url>
    <content><![CDATA[<p>什么是强化学习？<br>强化学习和监督学习、无监督学习的区别是什么？<br>强化学习适合解决什么样子的问题？<br>使用tensorflow进行深度学习算法实验时，如何调节超参数？<br>深度学习中的batch的大小对学习效果有何影响？<br>用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？<br>卷积神经网络CNN中池化层有什么作用？<br>请列举几种常见的激活函数。激活函数有什么作用？<br>神经网络中Dropout的作用？具体是怎么实现的？<br>利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？</p>
<p>如何解决不平衡数据集的分类问题？<br>残差网络为什么能做到很深层？<br>相比sigmoid激活函数ReLU激活函数有什么优势？<br>卷积神经网络中空洞卷积的作用是什么？<br>适用于移动端部署的网络结构都有哪些？<br>深度学习模型参数初始化都有哪些方法？<br>卷积神经网络为什么会具有平移等不变性？</p>
<span id="more"></span>

]]></content>
  </entry>
  <entry>
    <title>cv算法面试问题总结（二）</title>
    <url>/2021/09/29/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="问题列表"><a href="#问题列表" class="headerlink" title="问题列表"></a>问题列表</h1><ol>
<li>？？？ 判别模型和生成模型</li>
<li>如何决定算法是否收敛</li>
<li>正则的方法及特点</li>
<li>1*1卷积的作用</li>
<li>？？？ 无监督学习的方法有哪些</li>
<li>什么是感受野，增大感受野的方法</li>
<li>反卷积的棋盘效应和解决方法</li>
<li>神经网络参数量计算</li>
<li>？？？ 空洞卷积的原理和作用</li>
<li>？？？ 空洞卷积的感受野计算</li>
</ol>
<span id="more"></span>

<h1 id="问题及解答"><a href="#问题及解答" class="headerlink" title="问题及解答"></a>问题及解答</h1><h2 id="判别模型和生成模型"><a href="#判别模型和生成模型" class="headerlink" title="判别模型和生成模型"></a>判别模型和生成模型</h2><p>？？？</p>
<h2 id="如何决定算法是否收敛"><a href="#如何决定算法是否收敛" class="headerlink" title="如何决定算法是否收敛"></a>如何决定算法是否收敛</h2><ol>
<li><p>Loss 小于某个阈值</p>
</li>
<li><p>Loss趋于稳定，在某个之附近徘徊</p>
</li>
<li><p>迭代到一定的次数</p>
</li>
<li><p>看权值矩阵的变化，两次迭代权值变化很小</p>
</li>
</ol>
<h2 id="正则的方法及特点"><a href="#正则的方法及特点" class="headerlink" title="正则的方法及特点"></a>正则的方法及特点</h2><ol>
<li>正则的目的是防止过拟合，提高泛化能力</li>
<li>L1正则</li>
<li>L2正则</li>
<li>数据集扩增</li>
<li>dropout</li>
</ol>
<h2 id="1-1卷积的作用"><a href="#1-1卷积的作用" class="headerlink" title="1*1卷积的作用"></a>1*1卷积的作用</h2><ol>
<li>实现跨通道信息融合；不同通道上的一个线性组合，实际上就是加起来乘一个系数</li>
<li>feature map 通道数上的降维：<ol>
<li>假设输入特征维度是 100<em>100</em>128，卷积核的大小是5<em>5（stride=1，padding=2）通道数是256，经过卷积后输出的特征维度是（100-5+2</em>2）/1+1 = 100-》100<em>100</em>256 卷积参数量是128<em>5</em>5<em>256=819200 如果在5</em>5卷积之前使用一个64通道1<em>1的卷积，参数量是 128</em>1<em>1</em>64 + 64<em>5</em>5*256 = 417792</li>
</ol>
</li>
<li>增加非线性映射次数 1*1卷积之后会加一个非线性激活函数，使网络更深，也是网络更加具有判别信息的特征</li>
</ol>
<h2 id="无监督学习的方法有哪些"><a href="#无监督学习的方法有哪些" class="headerlink" title="无监督学习的方法有哪些"></a>无监督学习的方法有哪些</h2><h2 id="什么是感受野，增大感受野的方法"><a href="#什么是感受野，增大感受野的方法" class="headerlink" title="什么是感受野，增大感受野的方法"></a>什么是感受野，增大感受野的方法</h2><ol>
<li>感受野是卷积神经网络每一层输出的的feature map上的每个feature 在原图上映射的区域大小（原图：预处理resize，crop，wrap之后的图）</li>
<li>感受野越大，映射的原始图像的范围越广，可以蕴含更为全局，语义层次更高的信息</li>
<li>计算公式：一开始RF=1，然后RF= （RF-1）* stride + kernelsize （不管conv层还是pooling层，依次替换stride和kernelsize至最后）</li>
<li>增加感受野的方法：<ol>
<li>空洞卷积</li>
<li>增加pooling层，但会降低准确度 pooling会丢失信息</li>
<li>增大kernelsize， 会增加参数</li>
<li>增加卷积层的个数， 会面临梯度消失的问题。CPM中作者采用多阶段训练，并引入中间层监督来解决梯度消失的问题</li>
</ol>
</li>
</ol>
<h2 id="反卷积的棋盘效应和解决方法"><a href="#反卷积的棋盘效应和解决方法" class="headerlink" title="反卷积的棋盘效应和解决方法"></a>反卷积的棋盘效应和解决方法</h2><ol>
<li>反卷积是允许小图像中的点来绘制更大图像中的方块，很容易出现不均匀重叠，使得图像中的某个部分颜色比其他部分更深，也就是伪影。尤其是kernelsize不能被stride整除的时候。虽然网络可以通过学习权重来避免这种情况，但实践中很难完全避免</li>
<li>解决方法：<ol>
<li>修改反卷积形式<ol>
<li>确保反卷积核的大小可以被步长整除</li>
<li>网络末尾使用1*1的反卷积</li>
<li>调整卷积核权重</li>
</ol>
</li>
<li>修改上采样形式，采用插值方法代替反卷积进行上采样，如邻近差值和双线性差值</li>
<li>通过损失函数修正输出，在损失函数中加入total variation loss等损失函数，平滑输出图像，但图像边缘会模糊</li>
</ol>
</li>
</ol>
<h2 id="神经网络参数量计算"><a href="#神经网络参数量计算" class="headerlink" title="神经网络参数量计算"></a>神经网络参数量计算</h2><ol>
<li>带参数的层是：卷积层，BN层和全连接层。激活函数层，pooling层和Upsample层是没有参数的</li>
<li>卷积层参数计算：卷积核体积(Kw X Kh X Cin) X 卷积核个数Cout(也就是输出channel数) + 偏置项个数Cout (每个卷积核带有一个偏置项，但是不影响参数的数量级有时候会省略)</li>
<li>BN层的参数计算：2 X Cin(输入通道数) 有两个需要学习缩放因子和平移因子</li>
<li>FC层的参数计算：输入向量长度(和feature map相同size的一个卷积核)Ti X 输出向量长度To + 偏置量To  （全连接层逐渐被global average pooling取代 将最后一层的特征图 整张图进行一个均值化形成特征点，将这些特征点组合成最后的特征向量，通过softmax 进行计算）</li>
</ol>
<h2 id="空洞卷积的原理和作用"><a href="#空洞卷积的原理和作用" class="headerlink" title="空洞卷积的原理和作用"></a>空洞卷积的原理和作用</h2><h2 id="空洞卷积的感受野计算"><a href="#空洞卷积的感受野计算" class="headerlink" title="空洞卷积的感受野计算"></a>空洞卷积的感受野计算</h2>]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>总结</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>cv算法面试问题总结（五）</title>
    <url>/2021/10/01/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%94%EF%BC%89/</url>
    <content><![CDATA[<p>如何确定CNN的卷积核通道数和卷积输出层的通道数？<br>什么是卷积？<br>什么是CNN的池化pool层？<br>简述下什么是生成对抗网络<br>学梵高作画的原理是什么？<br>请简要介绍下tensorflow的计算图<br>你有哪些深度学习（rnn、cnn）调参的经验？<br>为什么不同的机器学习领域都可以使用CNN，CNN解决了这些领域的哪些共性问题？他是如何解决的？<br>LSTM结构推导，为什么比RNN好？<br>Sigmoid、Tanh、ReLu这三个激活函数有什么缺点或不足，有没改进的激活函数。</p>
<p>为什么引入非线性激励函数？<br>请问人工神经网络中为什么ReLu要好过于tanh和sigmoid function？<br>为什么LSTM模型中既存在sigmoid又存在tanh两种激活函数，而不是选择统一一种sigmoid或者tanh？这样做的目的是什么？<br>如何解决RNN梯度爆炸和弥散的问题？<br>什么样的数据集不适合用深度学习？<br>广义线性模型是怎被应用在深度学习中？<br>如何缓解梯度消失和梯度膨胀（微调、梯度截断、改良激活函数等）<br>简述神经网络的发展历史<br>深度学习常用方法<br>请简述神经网络的发展史。</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>总结</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>cv算法面试问题总结（八）</title>
    <url>/2021/10/06/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E5%85%AB%EF%BC%89/</url>
    <content><![CDATA[<p>神经网络中会用到批量梯度下降（BGD）吗？为什么用随机梯度下降（SGD）?<br>当神经网络的调参效果不好时，从哪些角度思考？（不要首先归结于overfiting）<br>请阐述下卷积神经网络CNN的基本原理(全网最通俗版)<br>神经网络输出层为什么通常使用softmax?<br>了解无人驾驶的核心技术么？<br>如何形象的理解LSTM的三个门<br>通过一张张动图形象的理解LSTM<br>如何理解反向传播算法BackPropagation<br>请问什么是softmax函数？<br>通俗理解BN(Batch Normalization)<br>批量归一化BN到底解决了什么问题？<br>如何理解随机梯度下降，以及为什么SGD能够收敛？<br>模拟退火算法能解决陷入局部最优的问题么<br>请说下常见优化方法各自的优缺点（BGD、SGD、MBGD、Momentum、NAG、Adagrad、Adadelta、RMSprop、Adam）<br>Adam算法的原理机制是怎么样的？它与相关的AdaGrad和RMSProp方法有什么区别</p>
<span id="more"></span>
]]></content>
  </entry>
  <entry>
    <title>cv算法面试问题总结（六）</title>
    <url>/2021/10/01/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E5%85%AD%EF%BC%89/</url>
    <content><![CDATA[<p>神经网络中激活函数的真正意义？一个激活函数需要具有哪些必要的属性？还有哪些属性是好的属性但不必要的？<br>梯度下降法的神经网络容易收敛到局部最优，为什么应用广泛？<br>简单说说CNN常用的几个模型<br>为什么很多做人脸的Paper会最后加入一个Local Connected Conv？<br>什么是梯度爆炸？<br>梯度爆炸会引发什么问题？<br>如何确定是否出现梯度爆炸？<br>如何修复梯度爆炸问题？</p>
<p>LSTM神经网络输入输出究竟是怎样的？<br>什么是RNN？<br>请详细介绍一下RNN模型的几种经典结构<br>简单说下sigmoid激活函数<br>如何从RNN起步，一步一步通俗理解LSTM（全网最通俗的LSTM详解）<br>CNN究竟是怎样一步一步工作的？<br>rcnn、fast-rcnn和faster-rcnn三者的区别是什么<br>在神经网络中，有哪些办法防止过拟合？<br>CNN是什么，CNN关键的层有哪些？<br>GRU是什么？GRU对LSTM做了哪些改动？</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>总结</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>cv算法面试问题总结（十）</title>
    <url>/2021/10/06/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E5%8D%81%EF%BC%89/</url>
    <content><![CDATA[<p>基于深度学习的目标检测技术演进：R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD<br>请简单解释下目标检测中的这个IOU评价函数（intersection-over-union）<br>KNN与K-means区别？<br>K-means选择初始点的方法有哪些,优缺点是什么?(列出两种以上)<br>简述线性分类器的原理(要求对权重矩阵进行剖析)<br>请简述下log对数、Hinge Loss(折页)、Cross-Entropy Loss(交叉熵)这三个损失函数<br>简述正则化与奥卡姆剃刀原则<br>图像尺寸为 7<em>7, 卷积窗口大小为3</em>3, 步长为3, 是否能输出图像?如果能,输出图像大小为多少?如果不能,说明原因?<br>如果最后一个卷积层和第一个全连接层参数量太大怎么办?<br>为什么说神经网络是端到端的网络?<br>当参数量 &gt;&gt; 样本量时候, 神经网络是如何预防过拟合?<br>什么是感受野？</p>
<p>简述你对CBIR(Content-based Image Retrieval基于内容的图像检索)的理解<br>什么是计算机视觉单词模型？<br>简述什么是Local Feature(局部特征算子)？<br>KD-Tree相比KNN来进行快速图像特征比对的好处在哪里?<br>简述encode和decode思想<br>输入图片尺寸不匹配CNN网络input时候的解决方式？（三种以上）<br>FCN与CNN最大的区别？<br>遇到class-imbalanced data（数据类目不平衡）问题怎么办？<br>简述孪生随机网络（Siamese Network）<br>DPM（Deformable Parts Model）算法流程<br>什么是NMS（Non-maximum suppression 非极大值抑制）?<br>列举出常见的损失函数(三个以上)?<br>做过目标检测项目么？比如Mask R-CNN和Python做一个抢车位神器<br>如何理解Faster RCNN<br>one-stage和two-stage目标检测方法的区别和优缺点？<br>请画下YOLOv3的网络结构<br>请简单说下YOLOv1,v2,v3,v4各自的特点与发展史<br>如何理解YOLO：YOLO详解<br>怎么理解YOLOv4<br>神经网络参数共享(parameter sharing)是指什么？<br>2021年网易互联网 计算机视觉 一面<br>美团实习算法岗<br>2021商汤-视频理解研究员-校招-技术面</p>
]]></content>
  </entry>
  <entry>
    <title>cv算法面试问题总结（四）</title>
    <url>/2021/10/01/cv%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="问题列表"><a href="#问题列表" class="headerlink" title="问题列表"></a>问题列表</h1><ol>
<li><p>神经网络中的Addition/concatenate区别</p>
</li>
<li><p>目标检测中的anchor机制？作用？</p>
</li>
<li><p>BN（Batch Normalization）的原理和作用</p>
</li>
<li><p>随机梯度下降相比全局梯度下降的好处</p>
</li>
<li><p>网络初始化时给网络赋予0的权重，这个网络能正常训练吗？</p>
</li>
<li><p>梯度消失和梯度爆炸的原因？</p>
</li>
<li><p>深度学习为什么在计算机视觉领域这么好？</p>
</li>
<li><p>什么是正则化？L1正则化和L2正则化有什么区别</p>
</li>
<li><p>常用的模型压缩方式有哪些</p>
</li>
<li><p>残差网络的设计思想和作用</p>
<span id="more"></span>

<h1 id><a href="#" class="headerlink" title></a></h1></li>
</ol>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>总结</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>hello-world</title>
    <url>/2021/09/29/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>kaggle比赛-Molecular Translation</title>
    <url>/2021/10/03/kaggle%E6%AF%94%E8%B5%9B-Molecular-Translation/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>kaggle比赛-NFL Helmet Assignment</title>
    <url>/2021/10/03/kaggle%E6%AF%94%E8%B5%9B-NFL-Helmet-Assignment/</url>
    <content><![CDATA[<p><a href="https://www.kaggle.com/c/nfl-health-and-safety-helmet-assignment">https://www.kaggle.com/c/nfl-health-and-safety-helmet-assignment</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>Pytorch</category>
        <category>深度学习</category>
        <category>项目比赛</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title>kaggle比赛-脑肿瘤检测</title>
    <url>/2021/09/03/kaggle%E6%AF%94%E8%B5%9B-%E8%84%91%E8%82%BF%E7%98%A4%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>数据集简介：脑肿瘤图片</p>
<p>算法简介：</p>
<p>Version1.0: EfficientDet 3D 迁移学习+微调</p>
<p>Version2.0: EfficientDet 3D + ResNet 101</p>
<p>预测结果： 当前排名500/1300</p>
<p>Version1.0  Score: 0.642 Rank: 500/1400</p>
<span id="more"></span>

<p>Version1.0:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys </span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pydicom</span><br><span class="line"><span class="keyword">from</span> pydicom.pixel_data_handlers.util <span class="keyword">import</span> apply_voi_lut</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data <span class="keyword">as</span> torch_data</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> sk_model_selection</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> torch_functional</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> efficientnet_pytorch_3d <span class="keyword">import</span> EfficientNet3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断数据集和EfficientNet模型的路径</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">&quot;../input/rsna-miccai-brain-tumor-radiogenomic-classification&quot;</span>):</span><br><span class="line">    data_directory = <span class="string">&#x27;../input/rsna-miccai-brain-tumor-radiogenomic-classification&#x27;</span></span><br><span class="line">    pytorch3dpath = <span class="string">&quot;../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D&quot;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    data_directory = <span class="string">&#x27;/media/roland/data/kaggle/rsna-miccai-brain-tumor-radiogenomic-classification&#x27;</span></span><br><span class="line">    pytorch3dpath = <span class="string">&quot;EfficientNet-PyTorch-3D&quot;</span></span><br><span class="line">    </span><br><span class="line">mri_types = [<span class="string">&#x27;FLAIR&#x27;</span>,<span class="string">&#x27;T1w&#x27;</span>,<span class="string">&#x27;T1wCE&#x27;</span>,<span class="string">&#x27;T2w&#x27;</span>]</span><br><span class="line">SIZE = <span class="number">256</span></span><br><span class="line">NUM_IMAGES = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">sys.path.append(pytorch3dpath)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dicom_image</span>(<span class="params">path, img_size=SIZE, voi_lut=<span class="literal">True</span>, rotate=<span class="number">0</span></span>):</span></span><br><span class="line">    dicom = pydicom.read_file(path) <span class="comment"># MRI扫描图像是多张dicom格式图像，通过pydicom</span></span><br><span class="line">    data = dicom.pixel_array</span><br><span class="line">    <span class="keyword">if</span> voi_lut:</span><br><span class="line">        data = apply_voi_lut(dicom.pixel_array, dicom)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        data = dicom.pixel_array</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> rotate &gt; <span class="number">0</span>:</span><br><span class="line">        rot_choices = [<span class="number">0</span>, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]</span><br><span class="line">        data = cv2.rotate(data, rot_choices[rotate])</span><br><span class="line">        </span><br><span class="line">    data = cv2.resize(data, (img_size, img_size))</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dicom_images_3d</span>(<span class="params">scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=<span class="string">&quot;FLAIR&quot;</span>, split=<span class="string">&quot;train&quot;</span>, rotate=<span class="number">0</span></span>):</span></span><br><span class="line"></span><br><span class="line">    files = <span class="built_in">sorted</span>(glob.glob(<span class="string">f&quot;<span class="subst">&#123;data_directory&#125;</span>/<span class="subst">&#123;split&#125;</span>/<span class="subst">&#123;scan_id&#125;</span>/<span class="subst">&#123;mri_type&#125;</span>/*.dcm&quot;</span>), </span><br><span class="line">               key=<span class="keyword">lambda</span> var:[<span class="built_in">int</span>(x) <span class="keyword">if</span> x.isdigit() <span class="keyword">else</span> x <span class="keyword">for</span> x <span class="keyword">in</span> re.findall(<span class="string">r&#x27;[^0-9]|[0-9]+&#x27;</span>, var)])</span><br><span class="line">    middle = <span class="built_in">len</span>(files)//<span class="number">2</span></span><br><span class="line">    num_imgs2 = num_imgs//<span class="number">2</span></span><br><span class="line">    p1 = <span class="built_in">max</span>(<span class="number">0</span>, middle - num_imgs2)</span><br><span class="line">    p2 = <span class="built_in">min</span>(<span class="built_in">len</span>(files), middle + num_imgs2)</span><br><span class="line">    img3d = np.stack([load_dicom_image(f, rotate=rotate) <span class="keyword">for</span> f <span class="keyword">in</span> files[p1:p2]]).T </span><br><span class="line">    <span class="keyword">if</span> img3d.shape[-<span class="number">1</span>] &lt; num_imgs:</span><br><span class="line">        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-<span class="number">1</span>]))</span><br><span class="line">        img3d = np.concatenate((img3d,  n_zero), axis = -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">min</span>(img3d) &lt; np.<span class="built_in">max</span>(img3d):</span><br><span class="line">        img3d = img3d - np.<span class="built_in">min</span>(img3d)</span><br><span class="line">        img3d = img3d / np.<span class="built_in">max</span>(img3d)</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> np.expand_dims(img3d,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">a = load_dicom_images_3d(<span class="string">&quot;00000&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(a.shape)</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">min</span>(a), np.<span class="built_in">max</span>(a), np.mean(a), np.median(a))</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>Pytorch</category>
        <category>深度学习</category>
        <category>项目比赛</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title>医疗影像dicom图像预处理-Pydicom</title>
    <url>/2021/10/06/%E5%8C%BB%E7%96%97%E5%BD%B1%E5%83%8Fdicom%E5%9B%BE%E5%83%8F%E9%A2%84%E5%A4%84%E7%90%86-Pydicom/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>pydicom是一个python中的第三方库，用于DICOM文件，主要为了以一种简单的”python式”方式检查和修改dicom数据而设计，可以提供给使用者轻松的修改，读写文件并转换成显式图像图片。</p>
<p>DICOM被广泛应用于放射医疗、心血管成像以及放射诊疗诊断设备（X射线，CT，核磁共振，超声等），并且在眼科和牙科等其它医学领域得到越来越深入广泛的应用。在数以万计的在用医学成像设备中，DICOM是部署最为广泛的医疗信息标准之一。当前大约有百亿级符合DICOM标准的医学图像用于临床使用。<br>患者的医学图像以DICOM文件格式进行存储，其中包含了图像信息以及患者的PHI（protected health information，即姓名、性别、年龄等），以及产生图像的设备的相关信息。</p>
<span id="more"></span>

<h1 id="人体内各介质的亨氏单位值"><a href="#人体内各介质的亨氏单位值" class="headerlink" title="人体内各介质的亨氏单位值"></a>人体内各介质的亨氏单位值</h1><p><img src="/2021/10/06/%E5%8C%BB%E7%96%97%E5%BD%B1%E5%83%8Fdicom%E5%9B%BE%E5%83%8F%E9%A2%84%E5%A4%84%E7%90%86-Pydicom/hu.png"></p>
<h1 id="pydicom基础操作"><a href="#pydicom基础操作" class="headerlink" title="pydicom基础操作"></a>pydicom基础操作</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pydicom</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dcm = pydicom.read_file(<span class="string">&#x27;test1/Image-100.dcm&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(dcm.<span class="built_in">dir</span>()) <span class="comment"># 查看有哪些方法，属性</span></span><br><span class="line"><span class="built_in">print</span>(dcm.<span class="built_in">dir</span>(<span class="string">&#x27;pat&#x27;</span>)) <span class="comment"># 查看有哪些pat(属性)</span></span><br><span class="line"><span class="comment"># 通过字典关键字来获取图像的数据元信息（当然也可以根据TAG号）</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">info = &#123;&#125;</span><br><span class="line"><span class="comment"># 从dcm 文件中提取patient信息</span></span><br><span class="line">info[<span class="string">&quot;PatientID&quot;</span>] = dcm.PatientID               <span class="comment"># 患者ID</span></span><br><span class="line"><span class="comment"># info[&quot;PatientName&quot;] = dcm.PatientName           # 患者姓名</span></span><br><span class="line"><span class="comment"># info[&quot;PatientBirthData&quot;] = dcm.PatientBirthData # 患者出生日期</span></span><br><span class="line"><span class="comment"># info[&quot;PatientAge&quot;] = dcm.PatientAge             # 患者年龄</span></span><br><span class="line"><span class="comment"># info[&#x27;PatientSex&#x27;] = dcm.PatientSex             # 患者性别</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从dcm 文件中提取study案例信息</span></span><br><span class="line"><span class="comment"># info[&#x27;StudyID&#x27;] = dcm.StudyID                   # 检查ID</span></span><br><span class="line"><span class="comment"># info[&#x27;StudyDate&#x27;] = dcm.StudyDate               # 检查日期</span></span><br><span class="line"><span class="comment"># info[&#x27;StudyTime&#x27;] = dcm.StudyTime               # 检查时间</span></span><br><span class="line"><span class="comment"># info[&#x27;InstitutionName&#x27;] = dcm.InstitutionName   # 机构名称</span></span><br><span class="line"><span class="comment"># info[&#x27;Manufacturer&#x27;] = dcm.Manufacturer         # 设备制造商</span></span><br><span class="line"><span class="comment"># info[&#x27;StudyDescription&#x27;]=dcm.StudyDescription   # 检查项目描述</span></span><br><span class="line"><span class="built_in">print</span>(info)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取图像唯一标识符</span></span><br><span class="line">uid = dcm.SOPInstanceUID</span><br><span class="line">img_arr = dcm.pixel_array</span><br><span class="line"><span class="built_in">print</span>(img_arr.shape)</span><br><span class="line">lens = img_arr.shape[<span class="number">0</span>] * img_arr.shape[<span class="number">1</span>] <span class="comment"># 获取像素点的数量</span></span><br><span class="line">tmp = np.reshape(img_arr,(lens,))</span><br><span class="line">max_val = <span class="built_in">max</span>(tmp)</span><br><span class="line">min_val = <span class="built_in">min</span>(tmp)</span><br><span class="line"><span class="comment"># 图像归一化</span></span><br><span class="line">img_arr = (img_arr-min_val)/(max_val-min_val)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">12</span>),dpi=<span class="number">250</span>) <span class="comment">#dpi每英寸点数，这张是1200*1200像素的图片</span></span><br><span class="line">plt.title(<span class="string">&quot;UID:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(uid))</span><br><span class="line">plt.imshow(img_arr,cmap=plt.cm.gray)<span class="comment">#颜色图谱（colormap), 默认绘制为RGB(A)颜色空间。</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改图片中的元素</span></span><br><span class="line"><span class="keyword">for</span> n,val <span class="keyword">in</span> <span class="built_in">enumerate</span>(dcm.pixel_array.flat):</span><br><span class="line">    <span class="keyword">if</span> val &lt; <span class="number">1300</span>:</span><br><span class="line">        dcm.pixel_array.flat[n] = <span class="number">0</span></span><br><span class="line">dcm.PixelData = dcm.pixel_array.tobytes()</span><br><span class="line">img_arr2 = dcm.pixel_array</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">12</span>),dpi=<span class="number">250</span>) <span class="comment">#dpi每英寸点数，这张是1200*1200像素的图片</span></span><br><span class="line">plt.title(<span class="string">&quot;UID:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(uid))</span><br><span class="line">plt.imshow(img_arr2,cmap=plt.cm.gray)<span class="comment">#颜色图谱（colormap), 默认绘制为RGB(A)颜色空间。</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="案例：肺结节图像预处理"><a href="#案例：肺结节图像预处理" class="headerlink" title="案例：肺结节图像预处理"></a>案例：肺结节图像预处理</h1><ol>
<li></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载必要的python包</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> dicom</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> scipy.ndimage</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> measure, morphology</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d.art3d <span class="keyword">import</span> Poly3DCollection</span><br><span class="line"></span><br><span class="line"><span class="comment"># 包含所有患者目录的根目录</span></span><br><span class="line">INPUT_FOLDER = <span class="string">&#x27;../input/sample_images/&#x27;</span></span><br><span class="line">patients = os.listdir(INPUT_FOLDER)</span><br><span class="line">patients.sort()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载一位患者的所有slice，按照顺序调整为等间隔扫描</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_scan</span>(<span class="params">path</span>):</span></span><br><span class="line">    slices = [dicom.read_file(path + <span class="string">&#x27;/&#x27;</span> + s) <span class="keyword">for</span> s <span class="keyword">in</span> os.listdir(path)]</span><br><span class="line">    <span class="comment">#按照扫描顺序叠加</span></span><br><span class="line">    slices.sort(key = <span class="keyword">lambda</span> x: <span class="built_in">float</span>(x.ImagePositionPatient[<span class="number">2</span>])) </span><br><span class="line">    <span class="comment"># 计算相邻扫描的间隔距离</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        slice_thickness = np.<span class="built_in">abs</span>(slices[<span class="number">0</span>].ImagePositionPatient[<span class="number">2</span>] - slices[<span class="number">1</span>].ImagePositionPatient[<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        slice_thickness = np.<span class="built_in">abs</span>(slices[<span class="number">0</span>].SliceLocation - slices[<span class="number">1</span>].SliceLocation)</span><br><span class="line">		</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> slices:</span><br><span class="line">        s.SliceThickness = slice_thickness</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> slices</span><br></pre></td></tr></table></figure>

<p>默认情况下，从DICOM文件中获得的值是HU这个单位。 需要解决这个问题。缩放斜率和截距由硬件制造商决定。<br>它指定从存储在磁盘表示中的像素到存储在内存表示中的像素的线性转换。磁盘存储的值定义为SV。而转化到内存中的像素值uints就需要两个dicom tag : Rescale intercept和Rescale slope。<br>OutputUnits=m∗SV+b<br>RescaleIntercept:b<br>RescaleSlope:m</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 排除扫描边界之外的数据，然后重新计算HU值（乘以重新缩放斜率并添加截距）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_pixels_hu</span>(<span class="params">slices</span>):</span></span><br><span class="line">    image = np.stack([s.pixel_array <span class="keyword">for</span> s <span class="keyword">in</span> slices])</span><br><span class="line">    <span class="comment"># 转换为int16，int16是ok的，因为所有的数值都应该 &lt;32k</span></span><br><span class="line">    image = image.astype(np.int16)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置边界外的元素为0</span></span><br><span class="line">    image[image == -<span class="number">2000</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换为HU单位</span></span><br><span class="line">    <span class="keyword">for</span> slice_number <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(slices)):</span><br><span class="line"></span><br><span class="line">        intercept = slices[slice_number].RescaleIntercept</span><br><span class="line">        slope = slices[slice_number].RescaleSlope</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> slope != <span class="number">1</span>:</span><br><span class="line">            image[slice_number] = slope * image[slice_number].astype(np.float64)</span><br><span class="line">            image[slice_number] = image[slice_number].astype(np.int16)</span><br><span class="line"></span><br><span class="line">        image[slice_number] += np.int16(intercept)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(image, dtype=np.int16)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 产看第i位患者的图像</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_img</span>():</span></span><br><span class="line">    first_patient = load_scan(INPUT_FOLDER + patients[<span class="number">0</span>])</span><br><span class="line">    first_patient_pixels = get_pixels_hu(first_patient)</span><br><span class="line">    plt.hist(first_patient_pixels.flatten(), bins=<span class="number">80</span>, color=<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Hounsfield Units (HU)&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示一个中间位置的切片</span></span><br><span class="line">    plt.imshow(first_patient_pixels[<span class="number">80</span>], cmap=plt.cm.gray)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p>统一像素间距spacing，spacing定义了图像像素的物理大小并且保证了实际距离测量的准确性。比如，如果知道x和y轴的像素间距为 0.4mm，那么在图像中的一条 10 像素的线就会有 4mm的长度。同样，由于知道图像像素中的宽和高(比如对于普通CT来说是 512×512)，就能够找到图像的实际尺寸了:512 × 0.4 mm = 204.8 mm。</p>
<p>在重采样过程中，让图像的spacing保持一致以及具体大小是多少是非常重要的：CNN中Conv操作被提出来的其中一个重要motivation就是图像中有相似的块能用共享的卷积来提取特征，因此对所有图像重采样能减少不同图像之间的不一致性，便于卷积操作提取共同的特征。</p>
<p>值得注意的是，图像的spacing保持一致，图像中像素值的个数（即图像分辨率）却不一定相同。而分割网络的框架是固定的，一般是需要输入图片的分辨率大小是一致的。所以通常在训练的时候是用一个固定大小的patch从图像中裁剪采样，在这个过程中原图分辨率不一样是不影响的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resample</span>(<span class="params">image, scan, new_spacing=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span>):</span></span><br><span class="line">    <span class="comment"># Determine current pixel spacing</span></span><br><span class="line">    spacing = np.array([scan[<span class="number">0</span>].SliceThickness] + scan[<span class="number">0</span>].PixelSpacing, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    resize_factor = spacing / new_spacing</span><br><span class="line">    new_real_shape = image.shape * resize_factor</span><br><span class="line">    new_shape = np.<span class="built_in">round</span>(new_real_shape)</span><br><span class="line">    real_resize_factor = new_shape / image.shape</span><br><span class="line">    new_spacing = spacing / real_resize_factor</span><br><span class="line"></span><br><span class="line">    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image, new_spacing</span><br><span class="line"></span><br><span class="line">pix_resampled, spacing = resample(first_patient_pixels, first_patient, [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape before resampling\t&quot;</span>, first_patient_pixels.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape after resampling\t&quot;</span>, pix_resampled.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画3D图像，用立方体为我们的3D对象创建一个近似网格</span></span><br><span class="line"><span class="comment"># 采用的阈值可以被用来绘制某些结构，例如所有组织或仅骨骼。 400是仅显示骨骼的阈值（见上面的Hounsfield单位表）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_3d</span>(<span class="params">image, threshold=-<span class="number">300</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Position the scan upright, </span></span><br><span class="line">    <span class="comment"># so the head of the patient would be at the top facing the camera</span></span><br><span class="line">    p = image.transpose(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    verts, faces = measure.marching_cubes(p, threshold)</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fancy indexing: `verts[faces]` to generate a collection of triangles</span></span><br><span class="line">    mesh = Poly3DCollection(verts[faces], alpha=<span class="number">0.70</span>)</span><br><span class="line">    face_color = [<span class="number">0.45</span>, <span class="number">0.45</span>, <span class="number">0.75</span>]</span><br><span class="line">    mesh.set_facecolor(face_color)</span><br><span class="line">    ax.add_collection3d(mesh)</span><br><span class="line"></span><br><span class="line">    ax.set_xlim(<span class="number">0</span>, p.shape[<span class="number">0</span>])</span><br><span class="line">    ax.set_ylim(<span class="number">0</span>, p.shape[<span class="number">1</span>])</span><br><span class="line">    ax.set_zlim(<span class="number">0</span>, p.shape[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>



<p>肺部切割</p>
<ul>
<li>阈值图像（-320 HU）</li>
<li>做连接组件，确定人周围的空气标签，在二进制图像中用1s填充</li>
<li>可选：对于扫描中的每个轴向切片，确定最大的固体连接组件（人体周围的身体+空气），并将其他组件设置为0。这样可以填充面罩中肺部的结构。</li>
<li>只保留最大的气袋（人体在这里和那里都有其他的气袋）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">largest_label_volume</span>(<span class="params">im, bg=-<span class="number">1</span></span>):</span></span><br><span class="line">    vals, counts = np.unique(im, return_counts=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    counts = counts[vals != bg]</span><br><span class="line">    vals = vals[vals != bg]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(counts) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> vals[np.argmax(counts)]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">segment_lung_mask</span>(<span class="params">image, fill_lung_structures=<span class="literal">True</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># not actually binary, but 1 and 2. </span></span><br><span class="line">    <span class="comment"># 0 is treated as background, which we do not want</span></span><br><span class="line">    binary_image = np.array(image &gt; -<span class="number">320</span>, dtype=np.int8)+<span class="number">1</span></span><br><span class="line">    labels = measure.label(binary_image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pick the pixel in the very corner to determine which label is air.</span></span><br><span class="line">    <span class="comment">#   Improvement: Pick multiple background labels from around the patient</span></span><br><span class="line">    <span class="comment">#   More resistant to &quot;trays&quot; on which the patient lays cutting the air </span></span><br><span class="line">    <span class="comment">#   around the person in half</span></span><br><span class="line">    background_label = labels[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Fill the air around the person</span></span><br><span class="line">    binary_image[background_label == labels] = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Method of filling the lung structures (that is superior to something like </span></span><br><span class="line">    <span class="comment"># morphological closing)</span></span><br><span class="line">    <span class="keyword">if</span> fill_lung_structures:</span><br><span class="line">        <span class="comment"># For every slice we determine the largest solid structure</span></span><br><span class="line">        <span class="keyword">for</span> i, axial_slice <span class="keyword">in</span> <span class="built_in">enumerate</span>(binary_image):</span><br><span class="line">            axial_slice = axial_slice - <span class="number">1</span></span><br><span class="line">            labeling = measure.label(axial_slice)</span><br><span class="line">            l_max = largest_label_volume(labeling, bg=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> l_max <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment">#This slice contains some lung</span></span><br><span class="line">                binary_image[i][labeling != l_max] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    binary_image -= <span class="number">1</span> <span class="comment">#Make the image actual binary</span></span><br><span class="line">    binary_image = <span class="number">1</span>-binary_image <span class="comment"># Invert it, lungs are now 1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove other air pockets insided body</span></span><br><span class="line">    labels = measure.label(binary_image, background=<span class="number">0</span>)</span><br><span class="line">    l_max = largest_label_volume(labels, bg=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> l_max <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment"># There are air pockets</span></span><br><span class="line">        binary_image[labels != l_max] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> binary_image</span><br><span class="line"></span><br><span class="line">segmented_lungs = segment_lung_mask(pix_resampled, <span class="literal">False</span>)</span><br><span class="line">segmented_lungs_fill = segment_lung_mask(pix_resampled, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plot_3d(segmented_lungs, <span class="number">0</span>)</span><br><span class="line">plot_3d(segmented_lungs_fill, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>当使用这个时，记得首先在它上面应用扩张形态学操作（即用圆形内核）。这会在所有方向上扩展蒙版。仅肺部的空气+结构将不包含所有结节，特别是它会遗漏那些粘在肺部侧面的结节，它们经常出现在那里！所以扩大面具一点:)</p>
<p>对于某些边缘情况，此分段可能会失败。它依赖于患者体外的空气不与肺部空气相连的事实。如果患者进行了气管造口术，情况也可能并非如此，不知道这是否存在于数据集中。此外，特别是噪声图像（例如由于下图中的起搏器），这种方法也可能失败。相反，身体中的第二大气袋将被分割。您可以通过检查蒙版对应的图像分数来识别这一点，对于这种情况，这将是非常小的。然后，你可以首先使用几毫米大小的内核进行形态学关闭操作以关闭这些孔，之后它应该可以工作（或者更简单地说，不要对此图像使用蒙版）。</p>
<p>数据归一化</p>
<p>目前所有的数值在-1024到2000左右。超过400的任何东西其实是不用关心的，因为只是一些具有不同辐射密度的骨骼。 常用的阈值集合在-1000到400之间。这里有一些代码可以使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MIN_BOUND = -<span class="number">1000.0</span></span><br><span class="line">MAX_BOUND = <span class="number">400.0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">image</span>):</span></span><br><span class="line">    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)</span><br><span class="line">    image[image&gt;<span class="number">1</span>] = <span class="number">1.</span></span><br><span class="line">    image[image&lt;<span class="number">0</span>] = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据零居中</span></span><br><span class="line"><span class="comment"># 将数据平均值设置为零。为此，只需从所有像素中减去平均像素值。</span></span><br><span class="line">PIXEL_MEAN = <span class="number">0.25</span> <span class="comment"># 假设均值为0.25</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zero_center</span>(<span class="params">image</span>):</span></span><br><span class="line">    image = image - PIXEL_MEAN</span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure>



<p>未完 参考 <a href="https://zhuanlan.zhihu.com/p/59413289">https://zhuanlan.zhihu.com/p/59413289</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>Python</category>
        <category>图像识别</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>医学图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像分割-Unet[项目应用]</title>
    <url>/2021/09/29/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2-Unet/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>Pytorch</category>
        <category>深度学习</category>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
        <tag>项目总结</tag>
      </tags>
  </entry>
  <entry>
    <title>图像分类-EfficientNet&amp;EfficientDet[项目应用]</title>
    <url>/2021/09/29/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB-EfficientNet/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>图像分类</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
        <tag>项目总结</tag>
        <tag>kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理基础-滤波器</title>
    <url>/2021/09/29/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80-%E6%BB%A4%E6%B3%A2%E5%99%A8/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>在图像处理中，经常需要对图像进行平滑去噪、锐化、边界增强等，这些功能可以通过滤波器filter来实现。</p>
<p>噪音的分类及如何添加</p>
<p>椒盐噪声：是一种随机出现的白点(salt)或者黑点(peppe)</p>
<p>高斯噪声：概率密度函数服从高斯分布（即正态分布）的一类噪声</p>
<p>常用滤波算法：</p>
<p>均值滤波器：把邻域内的平均值赋给中心元素。邻域内的像素权重是相等的；但不能保护细节，不能消除椒盐噪声</p>
<p>高斯滤波器：邻域内各个像素值不同权重的和，将中心点的权重增大，远离中心的的权重减小</p>
<p>中值滤波器：不使用权重，邻域内所有像素值的中间值来代替当前像素点的像素值</p>
<p>双边滤波器：同时考虑距离信息（距离越远，权重越小)和色彩信息（色彩差别越大，权重越小）</p>
<span id="more"></span>

<h1 id="滤波相关概念："><a href="#滤波相关概念：" class="headerlink" title="滤波相关概念："></a>滤波相关概念：</h1><p>图像的时域： 自变量是时间,即横轴是时间,纵轴是信号的变化。其动态信号x（t）是描述信号在不同时刻取值的函数</p>
<p>图像的频域：自变量是频率,即横轴是频率,纵轴是该频率信号的幅度,也就是通常说的频谱图。频谱图描述了信号的频率结构及频率与该频率信号幅度的关系</p>
<p>图像的频率： 图像的频率又称为空间频率，它反映了图像的像素灰度在空间中变化的情况</p>
<p>如何定量的测量图像的空间频率，最为常用的方法就是二维傅里叶变换。图像经过二维傅里叶变换后会形成与图像等大的复数矩阵，取其幅值形成幅度谱，取其相位形成相位谱。图像的频率能量分布主要体现在幅度谱中。通常习惯将低频成分放在幅度谱的中央，而将高频成分放在幅度谱边缘。</p>
<p>在图像频域里面，频率低的地方是比较平滑的，低频的区域中灰度值变化是比较小的；频率高的地方通常是边缘或者噪声，这些区域灰度值是突变的</p>
<p>高通滤波：让频率较高的部分通过，突出边缘等</p>
<p>低通滤波：保留频率比较低的部分，通常为平滑图像，弱化边缘，消除噪声</p>
<p>在时域中的滤波器和在频域中的滤波器组成了傅里叶变换对，这部分暂时不深入了。</p>
<h2 id="滤波器分类"><a href="#滤波器分类" class="headerlink" title="滤波器分类"></a>滤波器分类</h2><p>线性滤波： 对邻域中的像素的计算为线性运算时，如利用窗口函数进行平滑加权求和的运算，或者某种卷积运算，都可以称为线性滤波。常见的线性滤波有：方框滤波、均值滤波、高斯滤波、拉普拉斯滤波等等，通常线性滤波器之间只是模版的系数不同。</p>
<p>非线性滤波： 非线性滤波利用原始图像跟模版之间的一种逻辑关系得到结果，如最值滤波器，中值滤波器。比较常用的有中值滤波器和双边滤波器。</p>
<p>reference：<a href="https://blog.csdn.net/qq_44957388/article/details/105763906">https://blog.csdn.net/qq_44957388/article/details/105763906</a></p>
<h1 id="常见的滤波器："><a href="#常见的滤波器：" class="headerlink" title="常见的滤波器："></a>常见的滤波器：</h1><h2 id="均值滤波器"><a href="#均值滤波器" class="headerlink" title="均值滤波器"></a>均值滤波器</h2><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80-%E6%BB%A4%E6%B3%A2%E5%99%A8/%E5%9D%87%E5%80%BC.png"></p>
<h3 id="均值滤波的缺点"><a href="#均值滤波的缺点" class="headerlink" title="均值滤波的缺点"></a>均值滤波的缺点</h3><p>均值滤波本身存在着固有的缺陷，即它不能很好地保护图像细节，在图像去噪的同时也破坏了图像的细节部分，从而使图像变得模糊，不能很好地去除噪声点。特别是椒盐噪声。</p>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>均值模糊可以模糊图像以便得到感兴趣物体的粗略描述，也就是说，去除图像中的不相关细节，其中“不相关”是指与滤波器模板尺寸相比较小的像素区域，从而对图像有一个整体的认知。即为了对感兴趣的物体得到一个大致的整体的描述而模糊一幅图像，忽略细小的细节。</p>
<h2 id="高斯滤波器"><a href="#高斯滤波器" class="headerlink" title="高斯滤波器"></a>高斯滤波器</h2><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80-%E6%BB%A4%E6%B3%A2%E5%99%A8/%E9%AB%98%E6%96%AF.png"></p>
<p><strong>应用：</strong> 高斯滤波是一种线性平滑滤波器，对于服从正态分布的噪声有很好的抑制作用。在实际场景中，我们通常会假定图像包含的噪声为高斯白噪声，所以在许多实际应用的预处理部分，都会采用高斯滤波抑制噪声，如传统车牌识别等。</p>
<h2 id="中值滤波器"><a href="#中值滤波器" class="headerlink" title="中值滤波器"></a>中值滤波器</h2><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80-%E6%BB%A4%E6%B3%A2%E5%99%A8/%E4%B8%AD%E5%80%BC.png"></p>
<p>中值滤波不再采用加权求和的方式计算滤波结果，它用邻域内所有像素值的中间值来代替当前像素点的像素值。</p>
<p>中值滤波会取当前像素点及其周围临近像素点的像素值，一般有奇数个像素点，将这些像素值排序，将排序后位于中间位置的像素值作为当前像素点的像素值。</p>
<p>中值滤波对于斑点噪声（speckle noise）和椒盐噪声（salt-and-pepper<br>noise）来说尤其有用，因为它不依赖于邻域内那些与典型值差别很大的值，而且噪声成分很难被选上，所以可以在几乎不影响原有图像的情况下去除全部噪声。但是由于需要进行排序操作，中值滤波的计算量较大。</p>
<p>中值滤波器在处理连续图像窗函数时与线性滤波器的工作方式类似，但滤波过程却不再是加权运算。</p>
<h2 id="双边滤波器"><a href="#双边滤波器" class="headerlink" title="双边滤波器"></a>双边滤波器</h2><p>双边滤波是综合考虑空间信息和色彩信息的滤波方式，在滤波过程中能有效的保护图像内的边缘信息。</p>
<p>双边滤波在计算某一个像素点的像素值时，同时考虑距离信息（距离越远，权重越小)和色彩信息（色彩差别越大，权重越小）。既能去除噪声，又能较好的保护边缘信息。</p>
<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80-%E6%BB%A4%E6%B3%A2%E5%99%A8/%E5%8F%8C%E8%BE%B9.png"></p>
<p>在双边滤波中，计算左侧白色区域的滤波结果时：</p>
<p>对于白色的点，权重较大<br>对于黑色的点，与白色的色彩差别较大（0和255），所以可以将他们的权重设置为0<br>计算右侧黑色区域的滤波结果时：</p>
<p>对于黑色的点，权重较大<br>对于白色的点，与黑色的色彩差别较大（255和0），所以可以将他们的权重设置为0<br>这样，左侧白色的滤波结果仍是白色，黑色的像素点权重为0，对它不会有影响；右侧黑色的滤波结果仍是黑色，白色的像素点权重为0，对它不会有影响。所以，双边滤波会将边缘信息保留。</p>
<p>参考链接：<a href="https://blog.csdn.net/qq_44957388/article/details/105763906">https://blog.csdn.net/qq_44957388/article/details/105763906</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>基础操作</tag>
        <tag>噪音</tag>
        <tag>编程</tag>
        <tag>滤波器</tag>
      </tags>
  </entry>
  <entry>
    <title>图像识别-[2012]AlexNet</title>
    <url>/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-AlexNet/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>AlexNet是2012年ImageNet竞赛冠军获得者Alex Krizhevsky设计的</p>
<p>方法简述：AlexNet有6亿个参数和650,000个神经元，包含5个卷积层，有些层后面跟了max-pooling层，3个全连接层，为了减少过拟合，在全连接层使用了dropout</p>
<p>优点：</p>
<ol>
<li>使用Relu作为激活函数</li>
<li>使用Dropou避免过拟合</li>
<li>使用重叠的MaxPooling,让stride小于池化核的大小，池化层的输出有重叠和覆盖，提升了特征的丰富性</li>
<li>？？？提出LRN层局部响应归一化层？？？</li>
<li>使用分组卷机通过CUDA加速深度卷机网络的训练</li>
<li>数据增强，避免过拟合</li>
</ol>
<p>缺点：</p>
<ol>
<li>参数过多，计算量大</li>
<li>网络不深，准确率不高</li>
</ol>
<span id="more"></span>

<p>ImageNet是图像算法领域最常见的数据集，训练集包含120万张图片，验证集包含5万张图片，测试集包含15万张图片，这些图片分为了1000个类别，并且有多种不同的分辨率，</p>
<h1 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h1><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-AlexNet/%E7%BB%93%E6%9E%84.png"></p>
<h1 id="参数计算"><a href="#参数计算" class="headerlink" title="参数计算"></a>参数计算</h1><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-AlexNet/%E5%8F%82%E6%95%B0%E9%87%8F.png"></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>图像识别</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>图像识别-GoogLeNet</title>
    <url>/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/</url>
    <content><![CDATA[<h1 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h1><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：一般来说提升网络性能最直接的办法是增加网络深度（卷积层数）和宽度（神经元个数），但是伴随而来的是参数过多，容易过拟合；网络庞大计算复杂；梯度弥散，难以优化；所以需要设计一种模型：1. 让网络模型结构变得稀疏；2.能利用密集矩阵的高性能计算（大部分硬件是对密集矩阵计算优化的，稀疏矩阵计算时耗费的时间并没有减小）</p>
<p>方法简述：</p>
<p>Inception网络结构就是为了构造一种基础神经元结构，来搭建稀疏且有高性能的网络结构。</p>
<p>Inception V1: 卷积核分别采用1、3、5有不同的感受野，最后拼接意味着不同尺度特征的融合</p>
<p>Inception V2: 引入了BatchNormalization，</p>
<p>Inception V3: 引入分解</p>
<p>Inception V4: 结合Residual Connection</p>
<p>优点：</p>
<p>1）增加了网络的宽度；</p>
<p>2）增加了网络对尺度的适应性，提高了网络内部计算资源的利用率；</p>
<p>3）1x1减少网络参数，且起到信息融合的作用。</p>
<p>缺点：</p>
<span id="more"></span>



<h1 id="Inception-V1"><a href="#Inception-V1" class="headerlink" title="Inception V1:"></a>Inception V1:</h1><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/InceptionV1.png"></p>
<p>Inception的结构如图所示，其中1*1卷积主要用来降维，用了Inception之后整个网络结构的宽度和深度都可扩大，能够带来2-3倍的性能提升。</p>
<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/V1-architecture.png"></p>
<p>对Inception的结构做以下说明：</p>
<ol>
<li><p>采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合；</p>
</li>
<li><p>卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1后，只要分别设定pad=0、1、2，那么卷积后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了；</p>
</li>
<li><p>文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了;</p>
</li>
<li><p>网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</p>
</li>
<li><p>使用5x5的卷积核仍然会带来巨大的计算量。 为此，文章借鉴NIN2卷积神经网络 1*1 卷积核 ，采用1x1卷积核来进行降维。</p>
</li>
<li><p>该模型最后采用了average pooling来代替全连接层。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune。</p>
</li>
</ol>
<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/global-average-pooling.jpeg"></p>
<p>————————————————<br>参考链接：<a href="https://blog.csdn.net/weixin_42535423/article/details/103674098">https://blog.csdn.net/weixin_42535423/article/details/103674098</a></p>
<h1 id="Inception-V2"><a href="#Inception-V2" class="headerlink" title="Inception V2"></a>Inception V2</h1><p>作者在论文中提出了几个网路结构的设计准则</p>
<ol>
<li>避免表达瓶颈，尤其是网络早期：表达瓶颈也就是高度压缩的层，它会损失大量有用的信息。另外特征的维度（通道数）会逐渐增加，维度通道数不代表信息的多少</li>
<li>高维特征更容易处理：高维特征是经过多次非线性映射从而带有更多的判别信息，网络更容易训练</li>
<li>可以在低维特征时进行空间融合，不必担心信息过多损失，有助于加速训练</li>
<li>平衡网络深度和宽度，过宽或过深都不能达到最优</li>
</ol>
<p>改进：</p>
<ol>
<li><p>在输入时加入batch_normal层，加速收敛，减少使用dropout</p>
</li>
<li><p>将V1版本中的 5x5改进为两个3x3的卷积</p>
</li>
<li><p><strong>Inception-V2 其他优势与思考</strong>：</p>
<p>\1) 可以使用更高的学习率；</p>
<p>  解释：如果每层的scale不一致，实际上每层需要的学习率不一致。同一层不同维度的scale往往也需要不同大小的学习率，通常使用最小的那个学习率才能保证损失函数有效下降，Batch Normalization将每层、每维的scale保持一致，才可以直接使用较高的学习率进行优化。</p>
<p>\2) 移除或使用较低的dropout；</p>
<p>   解释：dropout是常用的防止overfit的方法，而导致overfit的位置往往在数据边界处，如果初始化权重就已经落在数据内部，overfit现象就可以得到一定的缓解。在论文中，最后的模型分别使用10%、5%和0%的dropout训练模型，与之前的40%-50%相比，可以大大提高训练速度。</p>
<p>\3) 降低L2权重衰减系数；</p>
<p>  解释：边界处的局部最优往往有几维的权重（斜率）较大，使用L2衰减可以缓解这一问题，使用Batch Normalization，就可以把这个值降低了，论文中降低为原来的5倍。</p>
<p>\4) 取消Local Response Normalization层；</p>
<p>  解释：由于使用了一种Normalization，再使用LRN就显得没那么必要了。而且LRN实际上也没那么work。</p>
<p>\5) 减少图像扭曲的使用；</p>
<p>  解释：由于现在训练epoch数降低，所以要对输入数据少做一些扭曲，让神经网络多看看真实的数据。</p>
<p>参考：Hugh_1：<a href="https://www.jianshu.com/p/ddfcf7ed08ab">https://www.jianshu.com/p/ddfcf7ed08ab</a></p>
</li>
</ol>
<h1 id="Inception-V3"><a href="#Inception-V3" class="headerlink" title="Inception V3"></a>Inception V3</h1><ol>
<li>将nxn的卷积代替为两个不对称的1xn和nx1的卷积，比如将3x3的卷积在输入输出filter一定的情况下分解为1x3和3x1的卷积，计算量减下33%，分解为2个2x2的卷积只能减少11%</li>
</ol>
<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/V3-architecture.png"></p>
<center>Inception V3 网络架构</center>

<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/V3-A.png">两个3X3取代5X5</p>
<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/V3-B.png"> 7X1和1X7取代7X7</p>
<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/V3-C.png"></p>
<p>3X1和1X3取代3X3</p>
<p>![](图像识别-GoogLeNet/V3-Grid Size Reduction.png)</p>
<p>下采样时采用conv+max pooling来取代max pooling，避免信息损失</p>
<p>![](图像识别-GoogLeNet/V3-Auxiliary Classifier.png)</p>
<p>Auxiliary Classifier辅助分类器： 在V3最后的 17×17 层的顶部仅使用 1 个辅助分类器，而不是使用 2 个辅助分类器，目的也不一样。在 GoogLeNet / Inception-v1 [4] 中，辅助分类器用于拥有更深的网络。在 Inception-v3 中，辅助分类器用作正则化。所以，实际上，在深度学习中，模块还是很直观的。</p>
<p>Inception-v2 [6] 中建议的批量归一化也用于辅助分类器</p>
<p><a href="https://sh-tsang.medium.com/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c">https://sh-tsang.medium.com/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c</a></p>
<p><strong>优点</strong>：</p>
<p>  1）加速计算（多余的计算能力可以用来加深网络），将1个conv拆成2个conv，使得网络深度进一步增加，增加了网络的非线性；</p>
<p>  2）网络输入从224x224变为了299x299，更加精细设计了35x35/17x17/8x8的模块。</p>
<p><strong>细节：</strong></p>
<p>  1）在辅助层加入了BN-auxiliary</p>
<p>  2）全连接层后面也进行BN操作。</p>
<h1 id="Inception-V4"><a href="#Inception-V4" class="headerlink" title="Inception V4"></a>Inception V4</h1><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-GoogLeNet/V4.png"></p>
<p>ResNet的结构可以极大地加速训练，同时性能也有提升。</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>图像识别</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>图像识别-ResNet</title>
    <url>/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-ResNet/</url>
    <content><![CDATA[<h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：<strong>训练集上的性能下降，可以排除过拟合，BN层的引入也基本解决了plain net的梯度消失和梯度爆炸问题。</strong>如果不是过拟合以及梯度消失导致的，那原因是什么？为什么非常深度的网络在增加更多层时会表现得更差？深度网络点退化（Degradation problem）问题</p>
<p>方法简述：</p>
<p>ResNet网络是参考了VGG19网络，在其基础上进行了修改，并通过短路机制加入了残差单元，如图5所示。变化主要体现在ResNet直接使用stride=2的卷积做下采样，并且用global average pool层替换了全连接层。ResNet的一个重要设计原则是：当feature map大小降低一半时，feature map的数量增加一倍，这保持了网络层的复杂度。</p>
<p>优点：</p>
<p>ResNet通过残差学习解决了深度网络的退化问题，让我们可以训练出更深的网络</p>
<p>缺点：</p>
<span id="more"></span>

<p>认知上，深层网络不会比浅层网络的表现更差。基本假设是第N+1层什么也没学到也只是简单的copy或者恒等映射了前一层的结果，也至少和前一层有相同的准确度。</p>
<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-ResNet/ResNet-Architecture.png"></p>
<p>参考：<a href="https://www.cnblogs.com/shine-lee/p/12363488.html">https://www.cnblogs.com/shine-lee/p/12363488.html</a></p>
<p>ResNet的设计有如下特点：</p>
<ul>
<li>与plain net相比，ResNet多了很多“旁路”，即shortcut路径，其首尾圈出的layers构成一个Residual Block；</li>
<li>ResNet中，所有的Residual Block都没有pooling层，<strong>降采样是通过conv的stride实现的</strong>；</li>
<li>分别在conv3_1、conv4_1和conv5_1 Residual Block，降采样1倍，同时feature map数量增加1倍，如图中虚线划定的block；</li>
<li><strong>通过Average Pooling得到最终的特征</strong>，而不是通过全连接层；</li>
<li>每个卷积层之后都紧接着BatchNorm layer，为了简化，图中并没有标出；</li>
</ul>
<p>ResNet结构非常容易修改和扩展，通过调整block内的channel数量以及堆叠的block数量，就可以很容易地调整网络的宽度和深度，来得到不同表达能力的网络，而不用过多地担心网络的“退化”问题，只要训练数据足够，逐步加深网络，就可以获得更好的性能表现。</p>
<p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-ResNet/resnet%E6%A8%A1%E5%9D%97.png"></p>
<h1 id="Residual-Block的分析与改进"><a href="#Residual-Block的分析与改进" class="headerlink" title="Residual Block的分析与改进"></a>Residual Block的分析与改进</h1><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-ResNet/ResNet%E6%94%B9%E8%BF%9B.png"></p>
<p>论文：<a href="https://arxiv.org/abs/1603.05027">https://arxiv.org/abs/1603.05027</a></p>
<p>新提出的Residual Block结构，具有更强的泛化能力，能更好地避免“退化”，堆叠大于1000层后，性能仍在变好。具体的变化在于</p>
<ul>
<li><strong>通过保持shortcut路径的“纯净”，可以让信息在前向传播和反向传播中平滑传递，这点十分重要。</strong>为此，如无必要，不引入1×11×1卷积等操作，同时将上图灰色路径上的ReLU移到了𝐹(𝑥)F(x)路径上。</li>
<li>在残差路径上，<strong>将BN和ReLU统一放在weight前作为pre-activation</strong>，获得了“Ease of optimization”以及“Reducing overfitting”的效果。</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>图像识别</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>图像识别-VGGNet</title>
    <url>/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-VGGNet/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：随着AlexNet提出，很多人开始利用卷积神经网络来解决图像识别的问题。一般的做法都是重复几层卷积网络，每个卷积网络之后接一些池化层，最后再加上几个全连接层。而如何更优的设计网络结构（深度，kernel size等）</p>
<p>方法简述：用更小更深的卷积核代替大的卷积核，较深的网络层次来提升深度学习的效果。</p>
<p>使用很小的3x3、步长为1的卷积核来扫描输入。两个3x3的卷积核堆起来，和一个5x5的卷积核的感受野一样；三个3x3的卷积核堆起来，其感受野等同于一个7x7的卷积核。</p>
<p>VGG16:</p>
<p>VGG19:</p>
<p>优点：</p>
<ol>
<li>结构简单 整个网络使用相同size 的卷积核（3X3）和最大池化（2X2）</li>
<li>证明更深的层可以使得函数具有更好的分辨能力</li>
<li>用多个较小的卷积核可以减少参数</li>
<li>去掉局部响应归一化模块</li>
</ol>
<p>缺点：</p>
<ol>
<li>计算耗费更多资源，参数量大（主要是全联接层导致的）， 内存空间占用高 140M</li>
</ol>
<span id="more"></span>

<h1 id="基本结构-VGG16"><a href="#基本结构-VGG16" class="headerlink" title="基本结构-VGG16"></a>基本结构-VGG16</h1><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-VGGNet/VGG16%E7%BB%93%E6%9E%84.png"></p>
<p>图片来源：<a href="https://www.cxyzjd.com/article/weixin_26726011/108260201">https://www.cxyzjd.com/article/weixin_26726011/108260201</a></p>
<h1 id="参数计算-VGG16"><a href="#参数计算-VGG16" class="headerlink" title="参数计算-VGG16"></a>参数计算-VGG16</h1><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-VGGNet/%E5%8F%82%E6%95%B0%E8%AE%A1%E7%AE%97.png"></p>
<h1 id="VGG16-VS-VGG19"><a href="#VGG16-VS-VGG19" class="headerlink" title="VGG16 VS VGG19"></a>VGG16 VS VGG19</h1><p><img src="/2021/09/29/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-VGGNet/VGG16VS19.png"></p>
<p>图片来源：<a href="https://www.cnblogs.com/jesse123/p/7110721.html">https://www.cnblogs.com/jesse123/p/7110721.html</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>图像识别</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>基于python的CUDA编程基础</title>
    <url>/2021/10/07/%E5%9F%BA%E4%BA%8Epython%E7%9A%84CUDA%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>GPU全名为Graphics Processing Unit，又称视觉处理器、图形显示卡。GPU负责渲染出2D、3D、VR效果，主要专注于计算机图形图像领域。无论是CPU还是GPU，在进行计算时，都需要用核心（Core）来做算术逻辑运算，比如加减乘与或非等。核心中有ALU（逻辑运算单元）和寄存器等电路。在进行计算时，一个核心只能顺序执行某项任务。不可能“吃着火锅唱着歌”，因为吃饭唱歌都占着嘴呢。</p>
<p>个人桌面电脑CPU只有2到8个CPU核心，数据中心的服务器上也只有20到40个左右CPU核心，GPU却有上千个核心。与CPU的核心不同，GPU的核心只能专注于某些特定的任务。知乎上有人把CPU比作大学教授，把GPU比作一个学校几千个小学生：同样是做加减法，几千个小学生所能做的计算，远比几十个大学教授要多得多。</p>
<span id="more"></span>

<p>CPU主要从主存（Main Memory）中读写数据，并通过总线（Bus）与GPU交互。GPU除了有超多计算核心外，也有自己独立的存储，被称之为显存。GPU核心在做计算时，只能直接从显存中读写数据，程序员需要在代码中指明哪些数据需要从内存和显存之间相互拷贝。这些数据传输都是在总线上，因此总线的传输速度和带宽成了部分计算任务的瓶颈。也因为这个瓶颈，很多计算任务并不适合放在GPU上，比如笔者这两年关注的推荐系统虽然也在使用深度学习，但因为输入是大规模稀疏特征，GPU加速获得的收益小于数据互相拷贝的时间损失。</p>
<p><img src="/2021/10/07/%E5%9F%BA%E4%BA%8Epython%E7%9A%84CUDA%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/cpu_gpu.png"></p>
<p>PU和主存被称为<strong>Host</strong>，GPU被称为<strong>Device</strong>。Host和Device概念会贯穿整个英伟达GPU编程。PU和主存被称为<strong>Host</strong>，GPU被称为<strong>Device</strong>。Host和Device概念会贯穿整个英伟达GPU编程。</p>
<p>2007年，英伟达发布了CUDA编程模型，软件开发人员从此可以使用CUDA在英伟达的GPU上进行并行编程。在此之前，GPU编程并不友好。</p>
<p>继CUDA之后，英伟达不断丰富其软件技术栈，提供了科学计算所必须的cuBLAS线性代数库，cuFFT快速傅里叶变换库等，当深度学习大潮到来时，英伟达提供了cuDNN深度神经网络加速库，目前常用的TensorFlow、PyTorch深度学习框架的底层大多基于cuDNN库。英伟达能在人工智能时代击败Intel、AMD等强大对手，很大一部分是因为它丰富的软件体系。这些软件工具库使研发人员专注于自己的研发领域，不用再去花大量时间学习GPU底层知识。CUDA对于GPU就像个人电脑上的Windows、手机上的安卓系统，一旦建立好生态，吸引了开发者，用户非常依赖这套软件生态体系。</p>
<p>CUDA是英伟达提供给开发者的一个GPU编程框架，程序员可以使用这个框架轻松地编写并行程序。本系列第一篇文章提到，CPU和主存被称为<strong>主机（Host）</strong>，GPU和显存（显卡内存）被称为<strong>设备（Device）</strong>，CPU无法直接读取显存数据，GPU无法直接读取主存数据，主机与设备必须通过总线（Bus）相互通信。</p>
<p>CUDA程序执行时会独霸一张卡，如果你的机器上有多张GPU卡，CUDA默认会选用0号卡。如果你与其他人共用这台机器，最好协商好谁在用哪张卡。一般使用<code>CUDA_VISIBLE_DEVICES</code>这个环境变量来选择某张卡。如选择5号GPU卡运行你的程序。</p>
<p>CUDA编程的基本流程为：</p>
<ol>
<li>初始化，并将必要的数据拷贝到GPU设备的显存上。</li>
<li>使用某个执行配置，以一定的并行粒度调用CUDA核函数。</li>
<li>CPU和GPU异步计算。</li>
<li>将GPU计算结果拷贝回主机。</li>
</ol>
<p>案例：计算两个2千万维的向量的加法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> cuda</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在GPU核函数上添加@cuda.jit装饰符，表示该函数是一个在GPU设备上运行的函数</span></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gpu_add</span>(<span class="params">a, b, result, n</span>):</span></span><br><span class="line">    <span class="comment"># a, b为输入向量，result为输出向量</span></span><br><span class="line">    <span class="comment"># 所有向量都是n维</span></span><br><span class="line">    <span class="comment"># 得到当前thread的索引</span></span><br><span class="line">    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line">    <span class="keyword">if</span> idx &lt; n :</span><br><span class="line">        result[idx] = a[idx] + b[idx]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    n = <span class="number">20000000</span></span><br><span class="line">    x = np.arange(n).astype(np.int32)</span><br><span class="line">    y = <span class="number">2</span> * x</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拷贝数据到设备端</span></span><br><span class="line">    x_device = cuda.to_device(x)</span><br><span class="line">    y_device = cuda.to_device(y)</span><br><span class="line">    <span class="comment"># 在显卡设备上初始化一块用于存放GPU计算结果的空间</span></span><br><span class="line">    gpu_result = cuda.device_array(n)</span><br><span class="line">    cpu_result = np.empty(n)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># CUDA配置</span></span><br><span class="line">    threads_per_block = <span class="number">1024</span></span><br><span class="line">    blocks_per_grid = math.ceil(n / threads_per_block)</span><br><span class="line">    start = time()</span><br><span class="line">    gpu_add[blocks_per_grid, threads_per_block](x_device, y_device, gpu_result, n)</span><br><span class="line">    cuda.synchronize() <span class="comment"># 等待当前设备上所有流中的所有核心完成。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;gpu vector add time &quot;</span> + <span class="built_in">str</span>(time() - start))</span><br><span class="line">    start = time()</span><br><span class="line">    cpu_result = np.add(x, y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;cpu vector add time &quot;</span> + <span class="built_in">str</span>(time() - start))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (np.array_equal(cpu_result, gpu_result.copy_to_host())):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;result correct!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>不同的执行配置会影响GPU程序的速度，一般需要多次调试才能找到较好的执行配置，在实际编程中，执行配置<code>[gridDim, blockDim]</code>应参考下面的方法：</p>
<ul>
<li>block运行在SM上，不同硬件架构（Turing、Volta、Pascal…）的CUDA核心数不同，一般需要根据当前硬件来设置block的大小<code>blockDim</code>（执行配置中第二个参数）。一个block中的thread数最好是32、128、256的倍数。==注意，限于当前硬件的设计，block大小不能超过1024。==</li>
<li>grid的大小<code>gridDim</code>（执行配置中第一个参数），即一个grid中block的个数可以由总次数<code>N</code>除以<code>blockDim</code>，并向上取整。</li>
</ul>
<p>例如，我们想并行启动1000个thread，可以将blockDim设置为128，<code>1000 ÷ 128 = 7.8</code>，向上取整为8。使用时，执行配置可以写成<code>gpuWork[8, 128]()</code>，CUDA共启动<code>8 * 128 = 1024</code>个thread，实际计算时只使用前1000个thread，多余的24个thread不进行计算。</p>
<p>注意，这几个变量比较容易混淆，再次明确一下：<code>blockDim</code>是block中thread的个数，一个block中的<code>threadIdx</code>最大不超过<code>blockDim</code>；<code>gridDim</code>是grid中block的个数，一个grid中的<code>blockIdx</code>最大不超过<code>gridDim</code>。</p>
<h1 id="PyTorch使用CUDA"><a href="#PyTorch使用CUDA" class="headerlink" title="PyTorch使用CUDA"></a>PyTorch使用CUDA</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hello World, Hello PyTorch &#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.__version__))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nCUDA is available:&#123;&#125;, version is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.cuda.is_available(), torch.version.cuda))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\ndevice_name: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.cuda.get_device_name(<span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>学习</category>
        <category>Python</category>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>常见的算法面试（一）</title>
    <url>/2021/10/03/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>新文章</title>
    <url>/2021/09/29/%E6%96%B0%E6%96%87%E7%AB%A0-1/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>新文章</title>
    <url>/2021/09/29/%E6%96%B0%E6%96%87%E7%AB%A0/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>空文档</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-KNN邻近算法</title>
    <url>/2021/10/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-KNN%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-主成分分析PCA</title>
    <url>/2021/10/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-K-means算法</title>
    <url>/2021/10/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-K-means%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>【未完成】机器学习-优化算法：牛顿法和拟牛顿法</title>
    <url>/2021/10/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%EF%BC%9A%E7%89%9B%E9%A1%BF%E6%B3%95%E5%92%8C%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>牛顿法（Newton method）和拟牛顿法（quasi Newton method）是求解无约束最优化问题的常用方法，有收敛速度快的优点。牛顿法是迭代算法，每一步都需求解目标函数的海塞矩阵（Hessian Matrix），计算比较复杂。拟牛顿法通过正定矩阵近似海塞矩阵的逆矩阵或海塞矩阵，简化了这一计算过程。</p>
<p>方法：</p>
<p>牛顿法：是使用函数F(x)的泰勒级数的前面几项来寻找方程F(x)=0的根。</p>
<p>拟牛顿法：牛顿法虽然收敛速度快，但是需要计算海塞矩阵的逆矩阵 ，而且有时目标函数的海塞矩阵无法保持正定，从而使得牛顿法失效。为了克服这两个问题，人们提出了拟牛顿法。这个方法的基本思想是：不用二阶偏导数而构造出可以近似海塞矩阵（或海塞矩阵的逆)的正定对称阵。不同的构造方法就产生了不同的拟牛顿法。</p>
<p>优点：</p>
<p>缺点：</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-决策树Decision Tree</title>
    <url>/2021/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91Decision-Tree/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：根据属性值做if … else …划分。问题在于先行选择哪个属性做划分是最优的？用什么标准来定量的去做这个选择？</p>
<p>方法简述：</p>
<p>ID3 利用信息增益来选择特征的。信息增益最大的特征来建立决策树的当前节点</p>
<p>C4.5 是根据“信息增益比”指标来做特征选择</p>
<p>CART(Classification and Regression Tree) 使用基尼系数</p>
<p>优点：</p>
<p>缺点：</p>
<p>决策树的回归用法</p>
<span id="more"></span>

<h1 id="ID3-决策算法"><a href="#ID3-决策算法" class="headerlink" title="ID3 决策算法"></a>ID3 决策算法</h1><h1 id="C4-5-决策算法"><a href="#C4-5-决策算法" class="headerlink" title="C4.5 决策算法"></a>C4.5 决策算法</h1><p>该算法解决了ID3算法中的一下问题：</p>
<ol>
<li><p>不能处理连续特征，</p>
<ol start="2">
<li>用信息增益作为标准容易偏向于取值较多的特征</li>
<li>缺失值处理的问</li>
<li>过拟合问题。</li>
</ol>
</li>
</ol>
<h1 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h1><p>该算法解决的是C4.5算法中的一下问题：</p>
<ol>
<li><p>由于决策树算法非常容易过拟合，因此对于生成的决策树必须要进行剪枝。</p>
</li>
<li><p>C4.5生成的是多叉树，即一个父节点可以有多个节点。很多时候，在计算机中二叉树模型会比多叉树运算效率高。如果采用二叉树，可以提高效率。</p>
</li>
<li><p>C4.5只能用于分类，如果能将决策树用于回归的话可以扩大它的使用范围。</p>
</li>
<li><p>C4.5由于使用了熵模型，里面有大量的耗时的对数运算,如果是连续值还有大量的排序运算。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-回归树Regression-Tree</title>
    <url>/2021/10/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%9B%9E%E5%BD%92%E6%A0%91Regression-Tree/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：决策树是解决分类问题的主要方法，分类是离散问题，但回归是连续问题，</p>
<p>方法简述： CART（Classification and Regression Tree）可以用来做回归，在分类问题中CART只用基尼系数作为特征选择和划分的依据；在回归问题中CART使用MSE(Mean Square Error)或者MAE(Mean Absolute Error)作为特征选择和划分的依据。每个叶子代表一个预测值，取值是连续的。</p>
<p>优点：</p>
<p>训练速度和预测速度较快；<br>善于获取数据集中的非线性关系；<br>了解数据集中的特征交互；<br>善于处理数据集中出现的异常值；<br>善于在数据集中找到最重要的特征；<br>不需要特征缩放；<br>结果可解释，并易于说明；</p>
<p>缺点：</p>
<p>预测精确度较低；<br>需要一些参数的调整；<br>不适用于小型数据集；<br>分离信号和噪声的效果不理想；<br>当新增数据时，不易更新模型；<br>在实践中很少使用，而是更多地使用集合树；<br>可能会出现过度拟合</p>
<span id="more"></span>

<p>参考：<a href="https://zhuanlan.zhihu.com/p/82054400">https://zhuanlan.zhihu.com/p/82054400</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-奇异值分解SVD</title>
    <url>/2021/10/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3SVD/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-支持向量机(SVM)</title>
    <url>/2021/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：逻辑回归是找到可以划分数据的超平面，但是如何找到最优的超平面来划分数据集呢？</p>
<p>方法简述：</p>
<p>线性支持向量机：</p>
<p>非线性支持向量机：</p>
<p>核函数：</p>
<p>软间隔支持向量机：</p>
<p>优点：</p>
<p>​    小规模数据集训练，比LR和随机森林准确率高，泛化能力强。</p>
<p>​    在非线性特征空间中效果较好，有大量的核函数可以使用来解决非线性分类问题</p>
<p>​    在高维度特征的分类问题和回归问题很有效，即便是特征维度大于样本量的时候</p>
<p>​    不需要依赖全部样本，仅仅使用一部分样本做支持向量来完成超平面决策</p>
<p>​    无局部极小值问题；（相对于神经网络等算法）</p>
<p>缺点：</p>
<p>​    SVM不能产生分类的概率值，</p>
<p>​    SVM对大规模训练数据集是不适用的，计算量十分复杂</p>
<p>​    解决非线性问题时，找到一个合适的核函数是比较困难的</p>
<p>​    多分类问题支持不友好</p>
<p>​    对缺失数据敏感</p>
<p>​    ？？？对于核函数的高维映射解释力不强，尤其是径向基函数；</p>
<p>应用：</p>
<p>文本分类领域效果最好的机器学习算法，在工业界主要应用在网页分类、微博情感分析、舆情监控、用户评论挖掘、文本过滤等诸多领域</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-朴素贝叶斯</title>
    <url>/2021/10/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-线性回归Linear Regression</title>
    <url>/2021/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92Linear-Regression/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：找到一系列的参数W，使得f(x) = XW 和真实输出Y之间无限接近或一致。</p>
<p>方法简述：</p>
<p>优点：直接，快速，可解释性高</p>
<p>缺点：基于一系列假设；对异常值敏感；对数据分布敏感；存在多重共线性，自相关，异方差问题；容易出现过拟合与欠拟合问题；</p>
<span id="more"></span>

<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>什么是回归模型？</p>
<p>回归是用来拟合输入变量和输出变量之间的关系，回归模型就是表示从输入变量到输出变量的映射函数。</p>
<p>所以线性回归的目标就是找到一系列的参数W，使得f(x) = XW 和真实输出Y之间无限接近或一致。</p>
<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><h2 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h2><p>​    分析数据，重新做数据清冼，将征工程。</p>
<p>​    扩充数据集，收集更多数据。</p>
<p>​    减少特征数量 。</p>
<p>​    **采用正则化方法</p>
<h2 id="欠拟合问题"><a href="#欠拟合问题" class="headerlink" title="欠拟合问题 **"></a>欠拟合问题 **</h2><p>​    分析数据，增加特征维度</p>
<p>​    ** 增加多项式特征阶数</p>
<p>​    ** 减小正则项的超参数系数</p>
<p>​    ** 局部加权回归 </p>
<h2 id="多重共线性"><a href="#多重共线性" class="headerlink" title="多重共线性"></a>多重共线性</h2><p>​    那共线性会引发什么问题。。。。：</p>
<p>1、模型参数估计不准确，有时甚至会出现回归系数的符号与实际情况完全相反的情况，比如逻辑上应该系数为正的特征系数 算出来为负。</p>
<p>2、本应该显著的自变量不显著，本不显著的自变量却呈现出显著性（也就是说，无法从p-值的大小判断出变量是否显著——下面会给一个例子）</p>
<p>3、多重共线性使参数估计值的方差增大，模型参数不稳定，也就是每次训练得到的权重系数差异都比较大。</p>
<p>其实多重共线性这样理解会简单很多:</p>
<p>假设原始的线性回归公式为：</p>
<p>y=w1<em>x1+w2</em>x2+w3*x3</p>
<p>训练完毕的线性回归公式为：</p>
<p>y=5x1+7x2+10x3,</p>
<p>此时加入一个新特征x4，假设x4和x3高度相关，x4=2x3,则</p>
<p>y=w1<em>x1+w2</em>x2+w3<em>x3+w4</em>x4=w1<em>x1+w2</em>x2+(w3+2w4)*x3</p>
<p>因为我们之前拟合出来的最优的回归方程为：</p>
<p>y=5x1+7x2+10x3</p>
<p>显然w3+2w4可以合并成一个新的权重稀疏 w5，则</p>
<p>y=w1<em>x1+w2</em>x2+w5*x3,显然：</p>
<p>y=w1<em>x1+w2</em>x2+w3<em>x3和y=w1</em>x1+w2<em>x2+w5</em>x3是等价的。。。。</p>
<p>那么最终最优的模型应该也是 y=5x1+7x2+10x3</p>
<p>但是考虑到引入了x4，所以w4和w3的权重是分开计算出来的，这就导致了</p>
<p>w5=10=w3+2w4，显然这个方程有无穷多的解，比如w3=4，w4=3，或者w4=-1，w3=12等，因此导致了模型系数估计的不稳定并且可能会出现负系数的问题。</p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="基于-Python-scikit-learn-工具包"><a href="#基于-Python-scikit-learn-工具包" class="headerlink" title="基于 Python scikit-learn 工具包"></a>基于 Python scikit-learn 工具包</h2><h2 id="Python自建实现"><a href="#Python自建实现" class="headerlink" title="Python自建实现"></a>Python自建实现</h2>]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-逻辑回归Logistic Regression</title>
    <url>/2021/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92Logistic-Regression/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>逻辑回归 = 线性回归+逻辑分布 （如：sigmoid函数）</p>
<p>背景问题：</p>
<p>回归是连续的，分类是离散的，怎么将解决分类问题转化为解决回归问题</p>
<p>方法简述：先拟合决策边界(不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。分类是离散的，但类别的概率是连续的，让模型拟合概率相关的一个指标（对数几率函数logit）</p>
<p>优点：</p>
<p>​    (1)对率函数任意阶可导，具有很好的数学性质，许多现有的数值优化算法都可以用来求最优解，训练速度快;</p>
<p>​    (2)简单易理解，模型的可解释性非常好，从特征的权重可以看到不同的特征对最后结果的影响;</p>
<p>​    (3)适合二分类问题，不需要缩放输入特征</p>
<p>​    (4)内存资源占用小，因为只需要存储各个维度的特征值;</p>
<p>​    (5)直接对分类可能性进行建模，无需事先假设数据分布，避免了假设分布不准确所带来的问题</p>
<p>​    (6)以概率的形式输出，对许多利用概率辅助决策的任务很有用</p>
<p>缺点：</p>
<p>​    (1)不能用于解决非线性问题</p>
<p>​    (2)对多重共线性数据较为敏感;</p>
<p>​    (3)很难处理数据不平衡的问题;</p>
<p>​    (4)准确率并不是很高，因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布;</p>
<p>​    (5)无法筛选特征</p>
<span id="more"></span>

<p>线性分类器：线性分类器的学习目标便是要在n维的数据空间中找到一个超平面，使得这个超平面可以将已知的数据点分为两个类别</p>
<p>逻辑回归不是解决回归问题是用来解决分类问题，本质就是假设数据符合这个分布，然后使用极大似然估计做参数的估计</p>
<h1 id="Logistic-分布函数"><a href="#Logistic-分布函数" class="headerlink" title="Logistic 分布函数"></a>Logistic 分布函数</h1><p>Logistic 分布是一种连续型的分布，它形状与正态分布的形状相似，但是 Logistic 分布的尾部更长，所以我们可以使用 Logistic 分布来建模比正态分布具有更长尾部和更高波峰的数据分布。在深度学习中常用到的 Sigmoid 函数就是 Logistic 的分布函数在 <img src="https://www.zhihu.com/equation?tex=%5Cmu=0,+%5Cgamma=1" alt="[公式]"> 的特殊形式。</p>
<p>logistic regression是使用线性回归的预测值逼近真实分类的对数几率，优点是：</p>
<ol>
<li>直接对分类概率建模，无需进行假设，避免假设带来的不准确</li>
<li>不仅可预测出类别，还能得到类别的概率，</li>
<li>对数几率函数是任意阶可导的函数，有许多数值优化算法都是可以求出最优解的</li>
</ol>
<p>损失函数：</p>
<p>优化的主要目标是找到一个方向，参数朝这个方向移动之后使得损失函数的值能够减小，</p>
<p>优点：</p>
<p>(1)对率函数任意阶可导，具有很好的数学性质，许多现有的数值优化算法都可以用来求最优解，训练速度快;</p>
<p>(2)简单易理解，模型的可解释性非常好，从<a href="https://www.cda.cn/map/tezheng/">特征</a>的权重可以看到不同的<a href="https://www.cda.cn/map/tezheng/">特征</a>对最后结果的影响;</p>
<p>(3)适合二分类问题，不需要缩放输入<a href="https://www.cda.cn/map/tezheng/">特征</a>;</p>
<p>(4)内存资源占用小，因为只需要存储各个维度的<a href="https://www.cda.cn/map/tezheng/">特征</a>值;</p>
<p>(5)直接对分类可能性进行建模，无需事先假设数据分布，避免了假设分布不准确所带来的问题</p>
<p>(6)以概率的形式输出，而非知识0.1判定，对许多利用概率辅助决策的任务很有用</p>
<p>缺点：</p>
<p>(1)不能用<a href="https://www.cda.cn/map/luojihuigui/">逻辑回归</a>去解决非线性问题，因为Logistic的决策面试线性的;</p>
<p>(2)对多重共线性数据较为敏感;</p>
<p>(3)很难处理数据不平衡的问题;</p>
<p>(4)准确率并不是很高，因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布;</p>
<p>(5)<a href="https://www.cda.cn/map/luojihuigui/">逻辑回归</a>本身无法筛选<a href="https://www.cda.cn/map/tezheng/">特征</a>，有时会用gbdt来筛选<a href="https://www.cda.cn/map/tezheng/">特征</a>，然后再上<a href="https://www.cda.cn/map/luojihuigui/">逻辑回归</a>。</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-集成算法-AdaBoost</title>
    <url>/2021/10/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95-AdaBoost/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-集成算法-随机森林</title>
    <url>/2021/10/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习经典算法概览</title>
    <url>/2021/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<p>这是一篇机器学习经典算法的简述，包含了线性回归、逻辑回归、支持向量机(SVM)、最近邻居(KNN)、决策树、k平均、随机森林、朴素贝叶斯、降维、梯度增强（更新ing）</p>
<span id="more"></span>

<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h1 id="集成算法-Ensemble-algorithms"><a href="#集成算法-Ensemble-algorithms" class="headerlink" title="集成算法 Ensemble algorithms"></a>集成算法 Ensemble algorithms</h1><p>将多个弱模型组合，弱模型单独训练，将哥哥弱模型的预测结果以某种方式结合完成总体的预测</p>
<p>主要问题在于找到可以组合的弱模型和弱模型结果的结合方式</p>
<ol>
<li>Boosting</li>
<li>Bagging</li>
<li>AdaBoost</li>
<li>Blending</li>
<li>Random Forest随机森林</li>
<li>** GBM（Gradient Boosting Machine）梯度推进机</li>
<li>** GBRT（Gradient Boosted Regression Tree） 梯度提升回归树</li>
</ol>
<p>优点：结合最优秀的模型们，可以得到更加优秀的预测结果</p>
<p>缺点：多模型融合计算量大</p>
<h3 id><a href="#" class="headerlink" title></a></h3><h1 id="决策树算法（Decision-Tree-Algorithm"><a href="#决策树算法（Decision-Tree-Algorithm" class="headerlink" title="决策树算法（Decision Tree Algorithm)"></a>决策树算法（Decision Tree Algorithm)</h1><p>Step1 选择分裂节点：当根据某个属性的值不能明确分到样本哪个类别是就将此属性作为节点对其分裂</p>
<p>Step2 选择一个合适的阈值进行分裂使其分类的错误率最小</p>
<h2 id="1-ID3"><a href="#1-ID3" class="headerlink" title="1.ID3"></a>1.ID3</h2>]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>概览</tag>
      </tags>
  </entry>
  <entry>
    <title>模型评价方法及指标</title>
    <url>/2021/10/01/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95%E5%8F%8A%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>深度学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>编程</tag>
        <tag>优化</tag>
        <tag>调参</tag>
      </tags>
  </entry>
  <entry>
    <title>模型过拟合问题解决方法</title>
    <url>/2021/10/01/%E6%A8%A1%E5%9E%8B%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>深度学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>编程</tag>
        <tag>优化</tag>
        <tag>调参</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习-[2013]ZFNet网络模型</title>
    <url>/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2013-ZFNet%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：在神经网络卷集训练中没有办法知道每一次卷积、每一次池化、每一次经过激活函数到底发生了什么，也不知道神经网络为什么取得了如此好的效果。ZFNet通过使用可视化技术揭示了神经网络各层到底在干什么，起到了什么作用。一旦知道了这些，如何调整我们的神经网络，往什么方向优化，就有了较好的依据。</p>
<p>方法简述：</p>
<p><strong>过程一：</strong>特征提取过程，输入图像-》卷积-》Relu激活-》最大化池化-》feature map</p>
<p><strong>过程二：</strong>特征还原过程，feature map-》反池化-》反Relu激活-》反卷积-》可视化（原始）图像</p>
<p><strong>结论一：</strong>CNN网络前面的层学习的是物理轮廓、边缘、颜色、纹理等特征，后面的层学习的是和类别相关的抽象特征</p>
<p><strong>结论二：</strong>CNN学习到的特征具有平移和缩放不变性，但是，没有旋转不变性</p>
<p><strong>结论三：</strong>CNN网络的特征提取具有通用性，这是后面微调的理论支持</p>
<p>优点：</p>
<ol>
<li>使用反卷积，可视化feature map 为模型优化提供依据</li>
<li>与AlexNet相比，前面层使用更小的卷积核和小的步长，保留更多特征</li>
<li>通过遮挡找到决定图像类别的关键部位，说明了深度增加时，网络课学习到更具区分的特征</li>
<li>训练时，底层参数收敛快，越高层的参数需要越长的训练时间</li>
</ol>
<p>缺点：</p>
<span id="more"></span>

<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2013-ZFNet%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/ZFNet.png"></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习-Bottleneck结构的理解</title>
    <url>/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Bottleneck%E7%BB%93%E6%9E%84%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习-RNN的改进：LSTM和GRU</title>
    <url>/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LSTM%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：RNN算法中越晚的输入对结果影响越大，但越晚的输入不一定是最重要的。如何治保留最重要的信息？</p>
<p>方法简述：</p>
<p>优点：</p>
<ol>
<li>长期信息可以有效的保留</li>
<li>挑选重要信息保留，不重要的信息会选择“遗忘”</li>
</ol>
<p>缺点：</p>
<span id="more"></span>



<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LSTM%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86/LSTMandGRU.png"></p>
<p>LSTM隐含层的中间单元 t 的数据流动示意图，它接收上一个单元 t-1 的输入 Ct-1 和 ht-1，当然还有来自本单元的输入 xt ，LSTM一共经过4步完成这些信息的处理，<strong>输出 t 单元的状态 Ct ，和 其输出 ht</strong> 。</p>
<ol>
<li>forget 阶段：这个阶段主要是对上一个节点传进来的输入进行<strong>选择性</strong>忘记。简单来说就是会 “忘记不重要的，记住重要的”。它是由 sigmoid 神经元层和按照点的乘法操作组成的，sigmoid函数的取值范围为0~1，当为0时，也就是不让当前单元的输入xt 的任何信息进入到这个单元的Ct中，如果等于1，意思是全部进入到 Ct 中。wf和bf是sigmoi节点的权重和偏执</li>
</ol>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LSTM%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86/forget.png"></p>
<ol start="2">
<li><p>选择记忆阶段。这个阶段将这个阶段的输入有选择性地进行“记忆”。</p>
<p>sigmoid层确定我们将要更新哪些值</p>
<p>tanh层创建新的值向量</p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LSTM%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86/input.png"></p>
</li>
<li><p>更新细胞状态Ct: 圈X是乘法，圈+是加法</p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LSTM%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86/update_ct.png"></p>
</li>
<li><p>输出阶段。这个阶段将决定哪些将会被当成当前状态的输出。Ct只不过隐含地输入给了下一个单元 t+1，因此，最后一步要确定 ht </p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LSTM%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86/output.png"></p>
<h1 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h1><p>对LSTM的有一种改动版本叫做带门的循环单元（Gated Recurrent Unit），简称为 GRU，在2014年由 Cho 等人提出，它将遗忘门和输入门结合为一个“更新门”，同时，将单元的状态 Ct 和隐藏状态合并为一体，这样的修改的结果是比我们上面介绍的标准的LSTM模型更加简化了，因此变得越来越受欢迎。</p>
</li>
</ol>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-LSTM%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86/GRU.png"></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习-Inception结构的理解</title>
    <url>/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Inception%E7%BB%93%E6%9E%84%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习-RNN循环神经网络</title>
    <url>/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：CNN算法的输入和输出基本是一对一的，不同的输入之间是没有联系的，但是需要处理序列数据（一串互相依赖的数据流）的场景就不能很好的完成了。比如文本，音频，股票走势等</p>
<p>方法简述：每一个样特征的训练计算的时候不仅仅考虑当前样本的值，也要考虑前一个样本的输出值</p>
<p>优点：</p>
<p>缺点：</p>
<ol>
<li>RNN 有短期记忆问题，无法处理很长的输入序列</li>
<li>训练 RNN 需要投入极大的成本</li>
</ol>
<span id="more"></span>



<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/RNN%E5%8D%95%E5%85%83%E7%BB%93%E6%9E%84.jpeg"></p>
<p>x是一个向量，它表示<strong>输入层</strong>的值（这里面没有画出来表示神经元节点的圆圈）；</p>
<p>s是一个向量，它表示<strong>隐藏层</strong>的值（可以想象这一层其实是多个节点，节点数与向量s的维度相同）；</p>
<p>U是输入层到隐藏层的<strong>权重矩阵</strong>，</p>
<p>o也是一个向量，它表示<strong>输出层</strong>的值；</p>
<p>V是隐藏层到输出层的<strong>权重矩阵</strong></p>
<p><strong>循环神经网络</strong>的<strong>隐藏层</strong>的值s不仅仅取决于当前这次的输入x，还取决于上一次<strong>隐藏层</strong>的值s。<strong>权重矩阵</strong> W就是<strong>隐藏层</strong>上一次的值作为这一次的输入的权重。</p>
<p>另外还有一个偏置项b</p>
<p>在计算时，<strong>每一步使用的参数U、W、b都是一样的，也就是说每个步骤的参数都是共享的，这是RNN的重要特点，一定要牢记。</strong></p>
<p>结构示意图</p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/RNN%E5%8D%95%E5%85%83.gif"></p>
<h1 id="N-vs-N模型"><a href="#N-vs-N模型" class="headerlink" title="N vs N模型"></a>N vs N模型</h1><p>Yi = Softmax(V*hi+c)</p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%BF%9E%E7%BB%AD%E7%BB%93%E6%9E%84.jpeg"></p>
<p>最后可以看出：<strong>这里的RNN的输入和输出序列是等长的</strong></p>
<h1 id="N-vs-1-模型"><a href="#N-vs-1-模型" class="headerlink" title="N vs 1 模型"></a>N vs 1 模型</h1><p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%BF%9E%E7%BB%AD%E7%BB%93%E6%9E%84n_1.jpeg"></p>
<p>这种结构通常用来处理序列分类问题。输入是一个序列输出为一个单独的值，如输入一段文字判别它所属的类别，输入一个句子判断其情感倾向，输入一段视频并判断它的类别等等。</p>
<h1 id="1-VS-N模型"><a href="#1-VS-N模型" class="headerlink" title="1 VS N模型"></a>1 VS N模型</h1><p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%BF%9E%E7%BB%AD%E7%BB%93%E6%9E%841_n.jpeg"></p>
<p>or</p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%BF%9E%E7%BB%AD%E7%BB%93%E6%9E%841_n2.jpeg"></p>
<p>这种1 VS N的结构可以处理的问题有：</p>
<ul>
<li>从图像生成文字（image caption），此时输入的X就是图像的特征，而输出的y序列就是一段句子</li>
<li>从类别生成语音或音乐等</li>
</ul>
<h1 id="N-vs-M-模型"><a href="#N-vs-M-模型" class="headerlink" title="N vs M 模型"></a>N vs M 模型</h1><p>这种结构又叫Encoder-Decoder模型，也可以称之为Seq2Seq模型。</p>
<p>原始的N vs N RNN要求序列等长，然而我们遇到的大部分问题序列都是不等长的，如机器翻译中，源语言和目标语言的句子往往并没有相同的长度。<strong>为此，Encoder-Decoder结构先将输入数据编码成一个上下文向量c：****拿到c之后，就用另一个RNN网络对其进行解码</strong>，这部分RNN网络被称为Decoder。具体做法就是将c当做之前的初始状态h0输入到Decoder中：</p>
<ol>
<li>c = h4</li>
<li>c = q(h4)</li>
<li>c = q(h1,h2,h3,h4)</li>
</ol>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/N_M.jpeg"></p>
<p>Or 另一种做法将C当作每一步输入</p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/N_M2.jpeg"></p>
<p>由于这种Encoder-Decoder结构不限制输入和输出的序列长度，因此应用的范围非常广泛，比如：</p>
<ul>
<li>机器翻译。Encoder-Decoder的最经典应用，事实上这一结构就是在机器翻译领域最先提出的</li>
<li>文本摘要。输入是一段文本序列，输出是这段文本序列的摘要序列。</li>
<li>阅读理解。将输入的文章和问题分别编码，再对其进行解码得到问题的答案。</li>
<li>语音识别。输入是语音信号序列，输出是文字序列。</li>
</ul>
<h1 id="Attention-机制"><a href="#Attention-机制" class="headerlink" title="Attention 机制"></a>Attention 机制</h1><p>问题：在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征c再解码，<strong>因此， c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。</strong>如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。</p>
<p>解决方法：Attention机制通过在每个时间输入不同的c来解决这个问题，下图是带有Attention机制的Decoder：</p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/attention1.jpeg"></p>
<p><strong>每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，我们用 a_ij衡量Encoder中第j阶段的hj和解码时第i阶段的相关性，最终Decoder中第i阶段的输入的上下文信息 c_i 就来自于所有 h_i对 a_ij的加权和。</strong></p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/attention2.jpeg"></p>
<p>Encoder中的h1、h2、h3、h4就可以分别看做是“我”、“爱”、“中”、“国”所代表的信息。在翻译成英语时，第一个上下文c1应该和“我”这个字最相关，因此对应的 <img src="https://www.zhihu.com/equation?tex=a_%7B11%7D" alt="[公式]"> 就比较大，而相应的 <img src="https://www.zhihu.com/equation?tex=a_%7B12%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=a_%7B13%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=a_%7B14%7D" alt="[公式]"> 就比较小。c2应该和“爱”最相关，因此对应的 <img src="https://www.zhihu.com/equation?tex=a_%7B22%7D" alt="[公式]"> 就比较大。最后的c3和h3、h4最相关，因此 <img src="https://www.zhihu.com/equation?tex=a_%7B33%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=a_%7B34%7D" alt="[公式]"> 的值就比较大。</p>
<p>至此，关于Attention模型，我们就只剩最后一个问题了，那就是：<strong>这些权重 <img src="https://www.zhihu.com/equation?tex=a_%7Bij%7D" alt="[公式]"> 是怎么来的？</strong></p>
<p>事实上， <img src="https://www.zhihu.com/equation?tex=a_%7Bij%7D" alt="[公式]"> 同样是从模型中学出的，它实际和Decoder的第i-1阶段的隐状态、Encoder第j个阶段的隐状态有关。</p>
<p>同样还是拿上面的机器翻译举例， <img src="https://www.zhihu.com/equation?tex=a_%7B1j%7D" alt="[公式]"> 的计算（此时箭头就表示对h’和 <img src="https://www.zhihu.com/equation?tex=h_j" alt="[公式]"> 同时做变换）：</p>
<p><img src="/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/attention3.jpeg"></p>
<p>Reference: <a href="https://zhuanlan.zhihu.com/p/28054589">https://zhuanlan.zhihu.com/p/28054589</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习-深度可分离卷积Depthwise Separable Conv</title>
    <url>/2021/10/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AFDepthwise-Separable-Conv/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>



]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习</title>
    <url>/2021/09/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>#设置标签<br>在编辑文章的时候，tags:后面是设置标签的地方，如果有多个标签的话，可以用下面两种办法来设置：</p>
<h2 id="设置小标签"><a href="#设置小标签" class="headerlink" title="设置小标签"></a>设置小标签</h2><p>在编辑文章的时候，tags:后面是设置标签的地方，如果有多个标签的话，可以用下面两种办法来设置：</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-Retina-Net</title>
    <url>/2021/09/29/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Retina-Net/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-R-CNN系列</title>
    <url>/2021/09/29/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-R-CNN%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-SSD系列</title>
    <url>/2021/09/29/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-SSD%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-YOLOv2</title>
    <url>/2021/10/01/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLOv2/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-YOLOv3</title>
    <url>/2021/10/01/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLOv3/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-YOLOv4</title>
    <url>/2021/10/01/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLOv4/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-YOLOv5</title>
    <url>/2021/10/01/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLOv5/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-YOLOx</title>
    <url>/2021/10/01/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLOx/</url>
    <content><![CDATA[<ul>
<li><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span></li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测-YOLOv1</title>
    <url>/2021/09/29/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLO%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>

<h1 id="YOLOv1"><a href="#YOLOv1" class="headerlink" title="YOLOv1"></a>YOLOv1</h1><ol>
<li><p>核心思想 回归思想</p>
<p>整张图作为网络的输入，在输出层回归Bounding Box的位置和Bounding Box的类别</p>
<p>相比Faster R-CNN虽然也是整张图输入，但Proposal+ classifier没变, 只是将Proposal也放在了CNN中</p>
</li>
<li><p>实现方法</p>
<ol>
<li>将整张图分为S*S的网格，如果某个object的中心落在这个网格中，这个网格就负责预测这个object</li>
<li>每个网格要预测B个bounding box，每个bounding box除了要回归自身的位置之外，还要附带预测一个confidence值。这个confidence代表了所预测的box中含有object的置信度和这个box预测的有多准两重信息</li>
<li>每个bounding Box 有五个值要预测(x, y, w, h)和confidence。每个网格还要预测一个类别信息，记为C类。则SxS个网格，每个网格要预测B个bounding box还要预测C个categories。输出就是S x S x (5*B+C)的一个tensor。</li>
<li><strong>简单的概括就是：</strong><ul>
<li>给个一个输入图像，首先将图像划分成7*7的网格；</li>
<li>对于每个网格，我们都预测2个边框（包括每个边框是目标的置信度以及每个边框区域在多个类别上的概率）；</li>
<li>根据上一步可以预测出7<em>7</em>2个目标窗口，然后根据阈值去除可能性比较低的目标窗口，最后NMS去除冗余窗口即可。</li>
</ul>
</li>
</ol>
</li>
<li><p>在YOLOv1的损失函数中：</p>
<p>Loss= 坐标预测的Loss + 含object的Box的confidence预测 + 不含object的Box的confidence预测 + 类别预测</p>
<p>只有当某个网格中有object的时候才对classification error进行惩罚。<br>只有当某个box predictor对某个ground truth box负责的时候，才会对box的coordinate error进行惩罚，而对哪个ground truth box负责就看其预测值和ground truth box的IoU是不是在那个cell的所有box中最大。<br>注：</p>
<p>YOLOv1方法模型训练依赖于物体识别标注数据，因此，对于非常规的物体形状或比例，YOLOv1的检测效果并不理想。<br>YOLOv1采用了多个下采样层，网络学到的物体特征并不精细，因此也会影响检测效果。<br>YOLOv1的loss函数中，大物体IOU误差和小物体IOU误差对网络训练中loss贡献值接近（虽然采用求平方根方式，但没有根本解决问题）。因此，对于小物体，小的IOU误差也会对网络优化过程造成很大的影响，从而降低了物体检测的定位准确性。<br>YOLO的缺点</p>
<p>YOLO对相互靠的很近的物体和很小的群体检测效果不好，这是因为一个网格中只预测了两个框，并且只属于一类；<br>同一类物体出现的新的不常见的长宽比和其他情况时，泛化能力偏弱；<br>由于损失函数的问题，定位误差是影响检测效果的主要原因。尤其是大小物体的处理上，还有待加强。</p>
</li>
</ol>
<h1 id="YOLOv2"><a href="#YOLOv2" class="headerlink" title="YOLOv2"></a>YOLOv2</h1><p>从预测<strong>更准确（Better）</strong>，<strong>速度更快（Faster）</strong>，<strong>识别对象更多（Stronger）</strong>这三个方面进行了改进。</p>
<p>采用联合训练算法的基本思路就是：同时在检测数据集和分类数据集上训练物体检测器（Object Detectors ），<strong>用检测数据集的数据学习物体的准确位置，用分类数据集的数据来增加分类的类别量、提升健壮性。</strong></p>
<ol>
<li><p>改进点</p>
<ol>
<li><p>BN层</p>
</li>
<li><p>高分辨率分类 224*224 -》448 * 448</p>
</li>
<li><h3 id="Convolution-with-anchor-boxes：-YOLOv1包含有全连接层，从而能直接预测Bounding-Boxes的坐标值。Faster-R-CNN算法只用卷积层与Region-Proposal-Network来预测Anchor-Box的偏移值与置信度，而不是直接预测坐标值，YOLOv2作者发现通过预测偏移量而不是坐标值能够简化问题，让神经网络学习起来更容易。"><a href="#Convolution-with-anchor-boxes：-YOLOv1包含有全连接层，从而能直接预测Bounding-Boxes的坐标值。Faster-R-CNN算法只用卷积层与Region-Proposal-Network来预测Anchor-Box的偏移值与置信度，而不是直接预测坐标值，YOLOv2作者发现通过预测偏移量而不是坐标值能够简化问题，让神经网络学习起来更容易。" class="headerlink" title="Convolution with anchor boxes： YOLOv1包含有全连接层，从而能直接预测Bounding Boxes的坐标值。Faster R-CNN算法只用卷积层与Region Proposal Network来预测Anchor Box的偏移值与置信度，而不是直接预测坐标值，YOLOv2作者发现通过预测偏移量而不是坐标值能够简化问题，让神经网络学习起来更容易。"></a>Convolution with anchor boxes： YOLOv1包含有全连接层，从而能直接预测Bounding Boxes的坐标值。Faster R-CNN算法只用卷积层与Region Proposal Network来预测Anchor Box的偏移值与置信度，而不是直接预测坐标值，YOLOv2作者发现通过预测偏移量而不是坐标值能够简化问题，让神经网络学习起来更容易。</h3><p>借鉴Faster RCNN的做法，YOLOv2也尝试采用先验框（anchor）。在每个grid预先设定一组不同大小和宽高比的边框，来覆盖整个图像的不同位置和多种尺度，这些先验框作为预定义的候选区在神经网络中将检测其中是否存在对象，以及微调边框的位置</p>
</li>
<li><p>YOLOv2的做法是对训练集中标注的边框进行K-means聚类分析，以寻找尽可能匹配样本的边框尺寸。</p>
<p><img src="/2021/09/29/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLO%E7%B3%BB%E5%88%97/1.png"></p>
</li>
</ol>
</li>
</ol>
<p>下面我们具体看看y1,y2,y3是如何而来的。<br>网络中作者进行了三次检测，分别是在32倍降采样，16倍降采样，8倍降采样时进行检测，这样在多尺度的feature map上检测跟SSD有点像。在网络中使用up-sample（上采样）的原因:网络越深的特征表达效果越好，比如在进行16倍降采样检测，如果直接使用第四次下采样的特征来检测，这样就使用了浅层特征，这样效果一般并不好。如果想使用32倍降采样后的特征，但深层特征的大小太小，因此YOLOv3使用了步长为2的up-sample（上采样），把32倍降采样得到的feature map的大小提升一倍，也就成了16倍降采样后的维度。同理8倍采样也是对16倍降采样的特征进行步长为2的上采样，这样就可以使用深层特征进行detection。</p>
<p>作者通过上采样将深层特征提取，其维度是与将要融合的特征层维度相同的（channel不同）。如下图所示，85层将13×13×256的特征上采样得到26×26×256，再将其与61层的特征拼接起来得到26×26×768。为了得到channel255，还需要进行一系列的3×3，1×1卷积操作，这样既可以提高非线性程度增加泛化性能提高网络精度，又能减少参数提高实时性。52×52×255的特征也是类似的过程。</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络-learning rate学习率的优化总结</title>
    <url>/2021/10/01/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-learning-rate%E5%AD%A6%E4%B9%A0%E7%8E%87%E7%9A%84%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>深度学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>编程</tag>
        <tag>优化</tag>
        <tag>调参</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络-损失函数</title>
    <url>/2021/10/01/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>Pytorch</category>
        <category>深度学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>编程</tag>
        <tag>优化</tag>
        <tag>调参</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络-权值初始化的方法</title>
    <url>/2021/10/01/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E6%9D%83%E5%80%BC%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>权值初始化的原因：1. 防止层激活输出在深度神经网络的正向传递过程中爆炸或消失。2. 有助于加速收敛。</p>
<p>权值初始化的方法：</p>
<p>常量初始化（constant）、高斯分布初始化（gaussian）、positive_unitball初始化、均匀分布初始化（uniform）、xavier初始化、msra初始化、双线性初始化（bilinear）</p>
<span id="more"></span>

<h1 id="常量初始化"><a href="#常量初始化" class="headerlink" title="常量初始化"></a>常量初始化</h1><h1 id="均匀分布初始化"><a href="#均匀分布初始化" class="headerlink" title="均匀分布初始化"></a>均匀分布初始化</h1><h1 id="高斯分布初始化"><a href="#高斯分布初始化" class="headerlink" title="高斯分布初始化"></a>高斯分布初始化</h1><h1 id="Xavier初始化"><a href="#Xavier初始化" class="headerlink" title="Xavier初始化"></a>Xavier初始化</h1><h1 id="MSRA初始化"><a href="#MSRA初始化" class="headerlink" title="MSRA初始化"></a>MSRA初始化</h1><h1 id="双线性初始化"><a href="#双线性初始化" class="headerlink" title="双线性初始化"></a>双线性初始化</h1>]]></content>
  </entry>
  <entry>
    <title>神经网络-梯度优化方法</title>
    <url>/2021/10/01/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E6%A2%AF%E5%BA%A6%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>深度学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>编程</tag>
        <tag>优化</tag>
        <tag>调参</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络-梯度爆炸和梯度消失</title>
    <url>/2021/10/01/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E5%92%8C%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>产生原因：反向传播过程的链式法则会导致梯度剧烈变化。如果每一层神经元对上一层的输出的偏导乘上权重结果都小于1的会导致梯度消失，如果都大于1的会导致梯度爆炸。</p>
<p>解决办法：</p>
<ol>
<li><p>预训练加微调</p>
</li>
<li><p>针对梯度爆炸：梯度剪切、权重正则，因此，如果发生梯度爆炸，权值的范数就会变的非常大，通过正则化项，可以<strong>部分</strong>限制<strong>梯度爆炸</strong>的发生。</p>
</li>
<li><p>使用不同的激活函数，用ReLU、Leaky-ReLU、P-ReLU、R-ReLU、Maxout等替代sigmoid函数。</p>
</li>
<li><p>BN（Batch Normalization），batchnorm就是通过对每一层的输出规范为均值和方差一致的方法，消除了w带来的放大缩小的影响，进而解决梯度消失和爆炸的问题。</p>
</li>
<li><p>残差的捷径（shortcut）</p>
</li>
<li><p>使用LSTM网络，它内部的“门”可以接下来更新的时候“记住”前几次训练的”残留记忆“</p>
</li>
</ol>
<span id="more"></span>

<h1 id="什么是梯度"><a href="#什么是梯度" class="headerlink" title="什么是梯度"></a>什么是梯度</h1><p>在深度神经网络中BP（反向传播算法）就是基于梯度下降策略，以目标的负梯度方向对参数进行调整， 参数的更新为 <img src="https://www.zhihu.com/equation?tex=w%5Cleftarrow+w+%5CDelta+w" alt="[公式]"> ，给定学习率 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> ，得出 <img src="https://www.zhihu.com/equation?tex=%5CDelta+w=-%5Calpha%5Cfrac%7B%5Cpartial+Loss%7D%7Bw%7D%5C" alt="[公式]"> 。如果更新第二层隐层的权值信息，根据链式求导法则，更新梯度信息为：</p>
<p><img src="https://pic1.zhimg.com/80/v2-718946a3296668d9221045a092e42fe0_1440w.jpg" alt="img"></p>
<p>上式中， <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f_%7B2%7D%7D%7B%5Cpartial+w_%7B2%7D%7D=f_%7B1%7D" alt="[公式]"> ，即第二隐藏层的输入。<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f_%7B4%7D%7D%7B%5Cpartial+f_%7B3%7D%7D" alt="[公式]"> 就是对激活函数进行求导，，那么层数增多的时候，最终的求出的梯度更新将以指数形式变化。</p>
<h1 id="梯度消失-弥散"><a href="#梯度消失-弥散" class="headerlink" title="梯度消失/弥散"></a>梯度消失/弥散</h1><p>根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都小于1的话，那么即使这个结果是0.99，在经过足够多层传播之后，误差对输入层的偏导会趋于0。</p>
<p>这种情况会导致靠近输入层的隐含层神经元调整极小。</p>
<p>梯度消失经常出现，一是在<strong>深层网络</strong>中，二是采用了<strong>不合适的损失函数</strong>，比如sigmoid。</p>
<h1 id="梯度爆炸"><a href="#梯度爆炸" class="headerlink" title="梯度爆炸"></a>梯度爆炸</h1><p>据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都大于1的话，在经过足够多层传播之后，误差对输入层的偏导会趋于无穷大。</p>
<p>这种情况又会导致靠近输入层的隐含层神经元调整变动极大。</p>
<p>梯度爆炸一般出现在深层网络和<strong>权值初始化值太大</strong>的情况下</p>
<p>注：事实上，在深度神经网络中，往往是梯度消失出现的更多一些。</p>
<h1 id="梯度消失-爆炸解决方案："><a href="#梯度消失-爆炸解决方案：" class="headerlink" title="梯度消失/爆炸解决方案："></a>梯度消失/爆炸解决方案：</h1><ol>
<li>预训练加微调</li>
</ol>
<p>此方法来自Hinton在2006年发表的一篇论文，Hinton为了解决梯度的问题，提出采取无监督逐层训练方法，其基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（fine-tunning）。Hinton在训练深度信念网络（Deep Belief Networks中，使用了这个方法，在各层预训练完成后，再利用BP算法对整个网络进行训练。此思想相当于是先寻找局部最优，然后整合起来寻找全局最优，此方法有一定的好处，但是目前应用的不是很多了。</p>
<ol start="2">
<li>针对梯度爆炸：梯度剪切、权重正则</li>
</ol>
<p>梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。</p>
<p>权重正则化：</p>
<p>正则化是通过对网络权重做正则限制过拟合，仔细看正则项在损失函数的形式：</p>
<p><img src="https://pic3.zhimg.com/80/v2-29298ec3d2b9094b20abdc6d9d7b1272_1440w.png" alt="img"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 是指正则项系数，因此，如果发生梯度爆炸，权值的范数就会变的非常大，通过正则化项，可以<strong>部分</strong>限制<strong>梯度爆炸</strong>的发生。</p>
<ol start="3">
<li><p>使用不同的激活函数</p>
<p>用ReLU、Leaky-ReLU、P-ReLU、R-ReLU、Maxout等替代sigmoid函数。</p>
</li>
<li><p>BN（Batch Normalization）</p>
<p>反向传播中，经过每一层的梯度会乘以该层的权重，举个简单例子：</p>
<p>正向传播中f2=f1(wT∗x+b)，那么反向传播中</p>
<p><img src="https://pic4.zhimg.com/80/v2-614cb67f4bfae76e8452b3dd06223cdf_1440w.png" alt="img"></p>
<p>反向传播式子中有w的存在，所以w的大小影响了梯度的消失和爆炸，batchnorm就是通过对每一层的输出规范为均值和方差一致的方法，消除了w带来的放大缩小的影响，进而解决梯度消失和爆炸的问题。</p>
</li>
<li><p>残差结构</p>
<p>残差的捷径（shortcut）</p>
</li>
<li><p>使用LSTM网络</p>
<p>LSTM内部复杂的“门”(gates)，LSTM通过它内部的“门”可以接下来更新的时候“记住”前几次训练的”残留记忆“，因此，经常用于生成文本中。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>梯度</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络-激活函数</title>
    <url>/2021/10/01/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>深度学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>编程</tag>
        <tag>优化</tag>
        <tag>调参</tag>
      </tags>
  </entry>
  <entry>
    <title>站内说明</title>
    <url>/2021/09/14/%E7%AB%99%E5%86%85%E8%AF%B4%E6%98%8E/</url>
    <content><![CDATA[<p>本blog是作为Leo同学的自我拓展过程中的自律自省记录</p>
<p>对该blog的计划是对一下类别和领域的学习与探索：</p>
<p>理论方面：</p>
<p>​    计算机视觉</p>
<p>​    深度学习算法</p>
<p>​    机器学习算法</p>
<p>Coding方面：</p>
<p>​    OpenCV</p>
<p>​    Python</p>
<p>​    Pytorch</p>
<p>​    </p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>概览</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机视觉CV算法概览（更新ing）</title>
    <url>/2021/08/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89CV%E7%AE%97%E6%B3%95%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<h1 id="图像识别"><a href="#图像识别" class="headerlink" title="图像识别"></a>图像识别</h1><h2 id="1-AlexNet"><a href="#1-AlexNet" class="headerlink" title="1. AlexNet"></a>1. AlexNet</h2><h2 id="2-VGGNet"><a href="#2-VGGNet" class="headerlink" title="2. VGGNet"></a>2. VGGNet</h2><h2 id="3-GoogLeNet"><a href="#3-GoogLeNet" class="headerlink" title="3. GoogLeNet"></a>3. GoogLeNet</h2><h2 id="4-ResNet"><a href="#4-ResNet" class="headerlink" title="4. ResNet"></a>4. ResNet</h2><h2 id="5-DenseNet"><a href="#5-DenseNet" class="headerlink" title="5. DenseNet"></a>5. DenseNet</h2><h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h2 id="1-R-CNN-系列"><a href="#1-R-CNN-系列" class="headerlink" title="1. R-CNN 系列"></a>1. R-CNN 系列</h2><h3 id="1-R-CNN"><a href="#1-R-CNN" class="headerlink" title="1. R-CNN"></a>1. R-CNN</h3><h3 id="2-Fast-R-CNN"><a href="#2-Fast-R-CNN" class="headerlink" title="2. Fast R-CNN"></a>2. Fast R-CNN</h3><h3 id="3-Faster-R-CNN"><a href="#3-Faster-R-CNN" class="headerlink" title="3. Faster R-CNN"></a>3. Faster R-CNN</h3><h2 id="2-Yolo系列"><a href="#2-Yolo系列" class="headerlink" title="2. Yolo系列"></a>2. Yolo系列</h2><h3 id="1-Yolo-V1"><a href="#1-Yolo-V1" class="headerlink" title="1.Yolo V1"></a>1.Yolo V1</h3><h3 id="2-Yolo-V2"><a href="#2-Yolo-V2" class="headerlink" title="2.Yolo V2"></a>2.Yolo V2</h3><h3 id="3-Yolo-V3"><a href="#3-Yolo-V3" class="headerlink" title="3.Yolo V3"></a>3.Yolo V3</h3><h3 id="4-Yolo-V4"><a href="#4-Yolo-V4" class="headerlink" title="4.Yolo V4"></a>4.Yolo V4</h3><h3 id="5-Yolo-V5"><a href="#5-Yolo-V5" class="headerlink" title="5.Yolo V5"></a>5.Yolo V5</h3><h2 id="3-SSD"><a href="#3-SSD" class="headerlink" title="3. SSD"></a>3. SSD</h2><h2 id="4-Retina-Net"><a href="#4-Retina-Net" class="headerlink" title="4. Retina-Net"></a>4. Retina-Net</h2><h1 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h1><h2 id="1-FCN"><a href="#1-FCN" class="headerlink" title="1. FCN"></a>1. FCN</h2><h2 id="2-Mask-R-CNN"><a href="#2-Mask-R-CNN" class="headerlink" title="2. Mask R-CNN"></a>2. Mask R-CNN</h2><h1 id="目标追踪"><a href="#目标追踪" class="headerlink" title="目标追踪"></a>目标追踪</h1><h2 id="1-Goturn"><a href="#1-Goturn" class="headerlink" title="1. Goturn"></a>1. Goturn</h2><h2 id="2"><a href="#2" class="headerlink" title="2."></a>2.</h2><h1 id="图像生成"><a href="#图像生成" class="headerlink" title="图像生成"></a>图像生成</h1><h2 id="1-GAN"><a href="#1-GAN" class="headerlink" title="1. GAN"></a>1. GAN</h2>]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
      </categories>
      <tags>
        <tag>概览</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机视觉模型库-timm</title>
    <url>/2021/10/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B%E5%BA%93-timm/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>Py<strong>T</strong>orch <strong>Im</strong>age <strong>M</strong>odels (<strong>timm</strong>)由Ross Wightman创建的深度学习库，是一个图像模型（models）、层（layers）、实用程序（utilities）、优化器（optimizers）、调度器（schedulers）、数据加载/增强（data-loaders / augmentations）和参考训练/验证脚本（reference training / validation scripts）的集合是一个关于SOTA的计算机视觉模型、层、实用工具、optimizers, schedulers, data-loaders, augmentations，可以复现ImageNet训练结果的训练/验证代码。</p>
<span id="more"></span>

<h1 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> timm </span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>)</span><br><span class="line"><span class="comment"># 如果是要创建一个预训练的模型，则只要设置pretrained=True即可。</span></span><br><span class="line">pretrained_resnet_34 = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 创建一个定制化类别数量的模型，只需设置num_classes</span></span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">x     = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">model(x).shape</span><br></pre></td></tr></table></figure>

<h1 id="预训练权重的模型列表"><a href="#预训练权重的模型列表" class="headerlink" title="预训练权重的模型列表"></a>预训练权重的模型列表</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 返回timm中所有模型的列表</span></span><br><span class="line">timm.list_models()</span><br><span class="line"><span class="comment"># 查看具有预训练权重的模型，只需设置pretrained=True</span></span><br><span class="line">avail_pretrained_models = timm.list_models(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 使用关键词检索模型架构</span></span><br><span class="line">all_densenet_models = timm.list_models(<span class="string">&#x27;*densenet*&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="其他设置"><a href="#其他设置" class="headerlink" title="其他设置"></a>其他设置</h1><h2 id="通道数设置"><a href="#通道数设置" class="headerlink" title="通道数设置"></a>通道数设置</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置单通道模型</span></span><br><span class="line">m = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>,pretrained=<span class="literal">True</span>, in_chans=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># single channel image</span></span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">m(x).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置多通道模型</span></span><br><span class="line">m = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>, pretrained=<span class="literal">True</span>, in_chans=<span class="number">25</span>)</span><br><span class="line"><span class="comment"># 25-channel image</span></span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">25</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"></span><br><span class="line">m(x).shape</span><br></pre></td></tr></table></figure>

<p>timm源码中的处理方式是</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将通道数设置为1时， timm简单地将原3通道权重相加成单通道权重，并更新权重的shape</span></span><br><span class="line">conv1_weight = state_dict[<span class="string">&#x27;conv1.weight&#x27;</span>]</span><br><span class="line">conv1_weight.<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将通道设置为8时，则先将原先的3通道复制3次变为9通道，然后选择前8个通道</span></span><br><span class="line">conv1_name = cfg[<span class="string">&#x27;first_conv&#x27;</span>]</span><br><span class="line">conv1_weight = state_dict[conv1_name + <span class="string">&#x27;.weight&#x27;</span>]</span><br><span class="line">conv1_type = conv1_weight.dtype</span><br><span class="line">conv1_weight = conv1_weight.<span class="built_in">float</span>()</span><br><span class="line">repeat = <span class="built_in">int</span>(math.ceil(in_chans / <span class="number">3</span>))</span><br><span class="line">conv1_weight = conv1_weight.repeat(<span class="number">1</span>, repeat, <span class="number">1</span>, <span class="number">1</span>)[:, :in_chans, :, :]</span><br><span class="line">conv1_weight *= (<span class="number">3</span> / <span class="built_in">float</span>(in_chans))</span><br><span class="line">conv1_weight = conv1_weight.to(conv1_type)</span><br><span class="line">state_dict[conv1_name + <span class="string">&#x27;.weight&#x27;</span>] = conv1_weight</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>学习</category>
        <category>Pytorch</category>
        <category>深度学习</category>
        <category>图像识别</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>轻量化网络-MobileNet</title>
    <url>/2021/09/29/%E8%BD%BB%E9%87%8F%E5%8C%96%E7%BD%91%E7%BB%9C-MobileNet/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景问题：</p>
<p>方法简述：</p>
<p>优点：</p>
<p>缺点：</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>学习</category>
        <category>cv算法</category>
        <category>深度学习</category>
        <category>轻量化模型</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>论文复现</tag>
      </tags>
  </entry>
</search>
